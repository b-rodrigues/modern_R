<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Statistical models | Modern R with the tidyverse</title>
  <meta name="description" content="This book will teach you how to use R to solve your statistical, data science and machine learning problems. Importing data, computing descriptive statistics, running regressions (or more complex machine learning models) and generating reports are some of the topics covered. No previous experience with R is needed." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Statistical models | Modern R with the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book will teach you how to use R to solve your statistical, data science and machine learning problems. Importing data, computing descriptive statistics, running regressions (or more complex machine learning models) and generating reports are some of the topics covered. No previous experience with R is needed." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Statistical models | Modern R with the tidyverse" />
  
  <meta name="twitter:description" content="This book will teach you how to use R to solve your statistical, data science and machine learning problems. Importing data, computing descriptive statistics, running regressions (or more complex machine learning models) and generating reports are some of the topics covered. No previous experience with R is needed." />
  

<meta name="author" content="Bruno Rodrigues" />


<meta name="date" content="2022-06-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="graphs.html"/>
<link rel="next" href="defining-your-own-functions.html"/>
<script src="libs/header-attrs-2.13/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modern R with the tidyverse</a></li>

<li class="divider"></li>
<li><a href="index.html#preface">Preface<span></span></a>
<ul>
<li><a href="index.html#note-to-the-reader">Note to the reader<span></span></a></li>
<li><a href="index.html#what-is-r">What is R?<span></span></a></li>
<li><a href="index.html#who-is-this-book-for">Who is this book for?<span></span></a></li>
<li><a href="index.html#why-this-book">Why this book?<span></span></a></li>
<li><a href="index.html#why-modern-r">Why <em>modern</em> R?<span></span></a></li>
<li><a href="index.html#what-is-rstudio">What is RStudio?<span></span></a></li>
<li><a href="index.html#what-to-expect-from-this-book">What to expect from this book?<span></span></a></li>
<li><a href="index.html#prerequisites">Prerequisites<span></span></a></li>
<li><a href="index.html#what-are-packages">What are packages?<span></span></a></li>
<li><a href="index.html#the-author">The author<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="getting-to-know-rstudio.html"><a href="getting-to-know-rstudio.html"><i class="fa fa-check"></i><b>1</b> Getting to know RStudio<span></span></a>
<ul>
<li class="chapter" data-level="1.1" data-path="getting-to-know-rstudio.html"><a href="getting-to-know-rstudio.html#panes"><i class="fa fa-check"></i><b>1.1</b> Panes<span></span></a></li>
<li class="chapter" data-level="1.2" data-path="getting-to-know-rstudio.html"><a href="getting-to-know-rstudio.html#console"><i class="fa fa-check"></i><b>1.2</b> Console<span></span></a></li>
<li class="chapter" data-level="1.3" data-path="getting-to-know-rstudio.html"><a href="getting-to-know-rstudio.html#scripts"><i class="fa fa-check"></i><b>1.3</b> Scripts<span></span></a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="getting-to-know-rstudio.html"><a href="getting-to-know-rstudio.html#the-help-pane"><i class="fa fa-check"></i><b>1.3.1</b> The help pane<span></span></a></li>
<li class="chapter" data-level="1.3.2" data-path="getting-to-know-rstudio.html"><a href="getting-to-know-rstudio.html#the-environment-pane"><i class="fa fa-check"></i><b>1.3.2</b> The Environment pane<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="getting-to-know-rstudio.html"><a href="getting-to-know-rstudio.html#options"><i class="fa fa-check"></i><b>1.4</b> Options<span></span></a></li>
<li class="chapter" data-level="1.5" data-path="getting-to-know-rstudio.html"><a href="getting-to-know-rstudio.html#keyboard-shortcuts"><i class="fa fa-check"></i><b>1.5</b> Keyboard shortcuts<span></span></a></li>
<li class="chapter" data-level="1.6" data-path="getting-to-know-rstudio.html"><a href="getting-to-know-rstudio.html#projects"><i class="fa fa-check"></i><b>1.6</b> Projects<span></span></a></li>
<li class="chapter" data-level="1.7" data-path="getting-to-know-rstudio.html"><a href="getting-to-know-rstudio.html#history"><i class="fa fa-check"></i><b>1.7</b> History<span></span></a></li>
<li class="chapter" data-level="1.8" data-path="getting-to-know-rstudio.html"><a href="getting-to-know-rstudio.html#plots"><i class="fa fa-check"></i><b>1.8</b> Plots<span></span></a></li>
<li class="chapter" data-level="1.9" data-path="getting-to-know-rstudio.html"><a href="getting-to-know-rstudio.html#addins"><i class="fa fa-check"></i><b>1.9</b> Addins<span></span></a></li>
<li class="chapter" data-level="1.10" data-path="getting-to-know-rstudio.html"><a href="getting-to-know-rstudio.html#packages"><i class="fa fa-check"></i><b>1.10</b> Packages<span></span></a></li>
<li class="chapter" data-level="1.11" data-path="getting-to-know-rstudio.html"><a href="getting-to-know-rstudio.html#exercises"><i class="fa fa-check"></i><b>1.11</b> Exercises<span></span></a>
<ul>
<li><a href="getting-to-know-rstudio.html#exercise-1">Exercise 1<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><i class="fa fa-check"></i><b>2</b> Objects, their classes and types, and useful R functions to get you started<span></span></a>
<ul>
<li class="chapter" data-level="2.1" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#the-numeric-class"><i class="fa fa-check"></i><b>2.1</b> The <code>numeric</code> class<span></span></a></li>
<li class="chapter" data-level="2.2" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#the-character-class"><i class="fa fa-check"></i><b>2.2</b> The <code>character</code> class<span></span></a></li>
<li class="chapter" data-level="2.3" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#the-factor-class"><i class="fa fa-check"></i><b>2.3</b> The <code>factor</code> class<span></span></a></li>
<li class="chapter" data-level="2.4" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#the-date-class"><i class="fa fa-check"></i><b>2.4</b> The <code>Date</code> class<span></span></a></li>
<li class="chapter" data-level="2.5" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#the-logical-class"><i class="fa fa-check"></i><b>2.5</b> The <code>logical</code> class<span></span></a></li>
<li class="chapter" data-level="2.6" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#vectors-and-matrices"><i class="fa fa-check"></i><b>2.6</b> Vectors and matrices<span></span></a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#the-c-function"><i class="fa fa-check"></i><b>2.6.1</b> The <code>c()</code> function<span></span></a></li>
<li class="chapter" data-level="2.6.2" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#cbind-and-rbind"><i class="fa fa-check"></i><b>2.6.2</b> <code>cbind()</code> and <code>rbind()</code><span></span></a></li>
<li class="chapter" data-level="2.6.3" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#the-matrix-class"><i class="fa fa-check"></i><b>2.6.3</b> The <code>matrix</code> class<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#the-list-class"><i class="fa fa-check"></i><b>2.7</b> The <code>list</code> class<span></span></a></li>
<li class="chapter" data-level="2.8" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#the-data.frame-and-tibble-classes"><i class="fa fa-check"></i><b>2.8</b> The <code>data.frame</code> and <code>tibble</code> classes<span></span></a></li>
<li class="chapter" data-level="2.9" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#formulas"><i class="fa fa-check"></i><b>2.9</b> Formulas<span></span></a></li>
<li class="chapter" data-level="2.10" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#models"><i class="fa fa-check"></i><b>2.10</b> Models<span></span></a></li>
<li class="chapter" data-level="2.11" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#null-na-and-nan"><i class="fa fa-check"></i><b>2.11</b> NULL, NA and NaN<span></span></a></li>
<li class="chapter" data-level="2.12" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#useful-functions-to-get-you-started"><i class="fa fa-check"></i><b>2.12</b> Useful functions to get you started<span></span></a>
<ul>
<li class="chapter" data-level="2.12.1" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#sequences"><i class="fa fa-check"></i><b>2.12.1</b> Sequences<span></span></a></li>
<li class="chapter" data-level="2.12.2" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#basic-string-manipulation"><i class="fa fa-check"></i><b>2.12.2</b> Basic string manipulation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html"><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#exercises-1"><i class="fa fa-check"></i><b>2.13</b> Exercises<span></span></a>
<ul>
<li><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#exercise-1-1">Exercise 1<span></span></a></li>
<li><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#exercise-2">Exercise 2<span></span></a></li>
<li><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#exercise-3">Exercise 3<span></span></a></li>
<li><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#exercise-4">Exercise 4<span></span></a></li>
<li><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#exercise-5">Exercise 5<span></span></a></li>
<li><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#exercise-6">Exercise 6<span></span></a></li>
<li><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#exercise-7">Exercise 7<span></span></a></li>
<li><a href="objects-their-classes-and-types-and-useful-r-functions-to-get-you-started.html#exercise-8">Exercise 8<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="reading-and-writing-data.html"><a href="reading-and-writing-data.html"><i class="fa fa-check"></i><b>3</b> Reading and writing data<span></span></a>
<ul>
<li class="chapter" data-level="3.1" data-path="reading-and-writing-data.html"><a href="reading-and-writing-data.html#the-swiss-army-knife-of-data-import-and-export-rio"><i class="fa fa-check"></i><b>3.1</b> The swiss army knife of data import and export: <code>{rio}</code><span></span></a></li>
<li class="chapter" data-level="3.2" data-path="reading-and-writing-data.html"><a href="reading-and-writing-data.html#writing-any-object-to-disk"><i class="fa fa-check"></i><b>3.2</b> Writing any object to disk<span></span></a></li>
<li class="chapter" data-level="3.3" data-path="reading-and-writing-data.html"><a href="reading-and-writing-data.html#using-rstudio-projects-to-manage-paths"><i class="fa fa-check"></i><b>3.3</b> Using RStudio projects to manage paths<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html"><i class="fa fa-check"></i><b>4</b> Descriptive statistics and data manipulation<span></span></a>
<ul>
<li class="chapter" data-level="4.1" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#a-data-exploration-exercice-using-base-r"><i class="fa fa-check"></i><b>4.1</b> A data exploration exercice using <em>base</em> R<span></span></a></li>
<li class="chapter" data-level="4.2" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#smoking-is-bad-for-you-but-pipes-are-your-friend"><i class="fa fa-check"></i><b>4.2</b> Smoking is bad for you, but pipes are your friend<span></span></a></li>
<li class="chapter" data-level="4.3" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#the-tidyverses-enfant-prodige-dplyr"><i class="fa fa-check"></i><b>4.3</b> The <code>{tidyverse}</code>’s <em>enfant prodige</em>: <code>{dplyr}</code><span></span></a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#a-first-taste-of-data-manipulation-with-dplyr"><i class="fa fa-check"></i><b>4.3.1</b> A first taste of data manipulation with <code>{dplyr}</code><span></span></a></li>
<li class="chapter" data-level="4.3.2" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#filter-the-rows-of-a-dataset-with-filter"><i class="fa fa-check"></i><b>4.3.2</b> Filter the rows of a dataset with <code>filter()</code><span></span></a></li>
<li class="chapter" data-level="4.3.3" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#select-columns-with-select"><i class="fa fa-check"></i><b>4.3.3</b> Select columns with <code>select()</code><span></span></a></li>
<li class="chapter" data-level="4.3.4" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#group-the-observations-of-your-dataset-with-group_by"><i class="fa fa-check"></i><b>4.3.4</b> Group the observations of your dataset with <code>group_by()</code><span></span></a></li>
<li class="chapter" data-level="4.3.5" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#get-summary-statistics-with-summarise"><i class="fa fa-check"></i><b>4.3.5</b> Get summary statistics with <code>summarise()</code><span></span></a></li>
<li class="chapter" data-level="4.3.6" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#adding-columns-with-mutate-and-transmute"><i class="fa fa-check"></i><b>4.3.6</b> Adding columns with <code>mutate()</code> and <code>transmute()</code><span></span></a></li>
<li class="chapter" data-level="4.3.7" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#joining-tibbles-with-full_join-left_join-right_join-and-all-the-others"><i class="fa fa-check"></i><b>4.3.7</b> Joining <code>tibble</code>s with <code>full_join()</code>, <code>left_join()</code>, <code>right_join()</code> and all the others<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#reshaping-and-sprucing-up-data-with-tidyr"><i class="fa fa-check"></i><b>4.4</b> Reshaping and sprucing up data with <code>{tidyr}</code><span></span></a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#pivot_wider-and-pivot_longer"><i class="fa fa-check"></i><b>4.4.1</b> <code>pivot_wider()</code> and <code>pivot_longer()</code><span></span></a></li>
<li class="chapter" data-level="4.4.2" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#fill-and-full_seq"><i class="fa fa-check"></i><b>4.4.2</b> <code>fill()</code> and <code>full_seq()</code><span></span></a></li>
<li class="chapter" data-level="4.4.3" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#put-order-in-your-columns-with-separate-unite-and-in-your-rows-with-separate_rows"><i class="fa fa-check"></i><b>4.4.3</b> Put order in your columns with <code>separate()</code>, <code>unite()</code>, and in your rows with <code>separate_rows()</code><span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#working-on-many-columns-with-across"><i class="fa fa-check"></i><b>4.5</b> Working on many columns with <code>across()</code><span></span></a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#filter-and-across"><i class="fa fa-check"></i><b>4.5.1</b> <code>filter()</code> and <code>across()</code><span></span></a></li>
<li class="chapter" data-level="4.5.2" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#selecting-and-renaming-with-across"><i class="fa fa-check"></i><b>4.5.2</b> Selecting and renaming with <code>across()</code><span></span></a></li>
<li class="chapter" data-level="4.5.3" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#group_by-and-across"><i class="fa fa-check"></i><b>4.5.3</b> <code>group_by()</code> and <code>across()</code><span></span></a></li>
<li class="chapter" data-level="4.5.4" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#summarise-across-many-columns"><i class="fa fa-check"></i><b>4.5.4</b> <code>summarise()</code> across many columns<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#other-useful-tidyverse-functions"><i class="fa fa-check"></i><b>4.6</b> Other useful <code>{tidyverse}</code> functions<span></span></a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#if_else-case_when-and-recode"><i class="fa fa-check"></i><b>4.6.1</b> <code>if_else()</code>, <code>case_when()</code> and <code>recode()</code><span></span></a></li>
<li class="chapter" data-level="4.6.2" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#lead-and-lag"><i class="fa fa-check"></i><b>4.6.2</b> <code>lead()</code> and <code>lag()</code><span></span></a></li>
<li class="chapter" data-level="4.6.3" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#ntile"><i class="fa fa-check"></i><b>4.6.3</b> <code>ntile()</code><span></span></a></li>
<li class="chapter" data-level="4.6.4" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#arrange"><i class="fa fa-check"></i><b>4.6.4</b> <code>arrange()</code><span></span></a></li>
<li class="chapter" data-level="4.6.5" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#tally-and-count"><i class="fa fa-check"></i><b>4.6.5</b> <code>tally()</code> and <code>count()</code><span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#special-packages-for-special-kinds-of-data-forcats-lubridate-and-stringr"><i class="fa fa-check"></i><b>4.7</b> Special packages for special kinds of data: <code>{forcats}</code>, <code>{lubridate}</code>, and <code>{stringr}</code><span></span></a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#section"><i class="fa fa-check"></i><b>4.7.1</b> 🐱🐱🐱🐱<span></span></a></li>
<li class="chapter" data-level="4.7.2" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#get-your-dates-right-with-lubridate"><i class="fa fa-check"></i><b>4.7.2</b> Get your dates right with <code>{lubridate}</code><span></span></a></li>
<li class="chapter" data-level="4.7.3" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#manipulate-strings-with-stringr"><i class="fa fa-check"></i><b>4.7.3</b> Manipulate strings with <code>{stringr}</code><span></span></a></li>
<li class="chapter" data-level="4.7.4" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#tidy-data-frames-with-tibble"><i class="fa fa-check"></i><b>4.7.4</b> Tidy data frames with <code>{tibble}</code><span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#list-columns"><i class="fa fa-check"></i><b>4.8</b> List-columns<span></span></a></li>
<li class="chapter" data-level="4.9" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#going-beyond-descriptive-statistics-and-data-manipulation"><i class="fa fa-check"></i><b>4.9</b> Going beyond descriptive statistics and data manipulation<span></span></a></li>
<li class="chapter" data-level="4.10" data-path="descriptive-statistics-and-data-manipulation.html"><a href="descriptive-statistics-and-data-manipulation.html#exercises-2"><i class="fa fa-check"></i><b>4.10</b> Exercises<span></span></a>
<ul>
<li><a href="descriptive-statistics-and-data-manipulation.html#exercise-1-2">Exercise 1<span></span></a></li>
<li><a href="descriptive-statistics-and-data-manipulation.html#exercise-2-1">Exercise 2<span></span></a></li>
<li><a href="descriptive-statistics-and-data-manipulation.html#exercise-3-1">Exercise 3<span></span></a></li>
<li><a href="descriptive-statistics-and-data-manipulation.html#exercise-4-1">Exercise 4<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="graphs.html"><a href="graphs.html"><i class="fa fa-check"></i><b>5</b> Graphs<span></span></a>
<ul>
<li class="chapter" data-level="5.1" data-path="graphs.html"><a href="graphs.html#resources"><i class="fa fa-check"></i><b>5.1</b> Resources<span></span></a></li>
<li class="chapter" data-level="5.2" data-path="graphs.html"><a href="graphs.html#examples"><i class="fa fa-check"></i><b>5.2</b> Examples<span></span></a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="graphs.html"><a href="graphs.html#barplots"><i class="fa fa-check"></i><b>5.2.1</b> Barplots<span></span></a></li>
<li class="chapter" data-level="5.2.2" data-path="graphs.html"><a href="graphs.html#scatter-plots"><i class="fa fa-check"></i><b>5.2.2</b> Scatter plots<span></span></a></li>
<li class="chapter" data-level="5.2.3" data-path="graphs.html"><a href="graphs.html#density"><i class="fa fa-check"></i><b>5.2.3</b> Density<span></span></a></li>
<li class="chapter" data-level="5.2.4" data-path="graphs.html"><a href="graphs.html#line-plots"><i class="fa fa-check"></i><b>5.2.4</b> Line plots<span></span></a></li>
<li class="chapter" data-level="5.2.5" data-path="graphs.html"><a href="graphs.html#facets"><i class="fa fa-check"></i><b>5.2.5</b> Facets<span></span></a></li>
<li class="chapter" data-level="5.2.6" data-path="graphs.html"><a href="graphs.html#pie-charts"><i class="fa fa-check"></i><b>5.2.6</b> Pie Charts<span></span></a></li>
<li class="chapter" data-level="5.2.7" data-path="graphs.html"><a href="graphs.html#adding-text-to-plots"><i class="fa fa-check"></i><b>5.2.7</b> Adding text to plots<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="graphs.html"><a href="graphs.html#customization"><i class="fa fa-check"></i><b>5.3</b> Customization<span></span></a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="graphs.html"><a href="graphs.html#changing-titles-axes-labels-options-mixing-geoms-and-changing-themes"><i class="fa fa-check"></i><b>5.3.1</b> Changing titles, axes labels, options, mixing geoms and changing themes<span></span></a></li>
<li class="chapter" data-level="5.3.2" data-path="graphs.html"><a href="graphs.html#colour-schemes"><i class="fa fa-check"></i><b>5.3.2</b> Colour schemes<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="graphs.html"><a href="graphs.html#saving-plots-to-disk"><i class="fa fa-check"></i><b>5.4</b> Saving plots to disk<span></span></a></li>
<li class="chapter" data-level="5.5" data-path="graphs.html"><a href="graphs.html#exercises-3"><i class="fa fa-check"></i><b>5.5</b> Exercises<span></span></a>
<ul>
<li><a href="graphs.html#exercise-1-3">Exercise 1<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="statistical-models.html"><a href="statistical-models.html"><i class="fa fa-check"></i><b>6</b> Statistical models<span></span></a>
<ul>
<li class="chapter" data-level="6.1" data-path="statistical-models.html"><a href="statistical-models.html#terminology"><i class="fa fa-check"></i><b>6.1</b> Terminology<span></span></a></li>
<li class="chapter" data-level="6.2" data-path="statistical-models.html"><a href="statistical-models.html#fitting-a-model-to-data"><i class="fa fa-check"></i><b>6.2</b> Fitting a model to data<span></span></a></li>
<li class="chapter" data-level="6.3" data-path="statistical-models.html"><a href="statistical-models.html#diagnostics"><i class="fa fa-check"></i><b>6.3</b> Diagnostics<span></span></a></li>
<li class="chapter" data-level="6.4" data-path="statistical-models.html"><a href="statistical-models.html#interpreting-models"><i class="fa fa-check"></i><b>6.4</b> Interpreting models<span></span></a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="statistical-models.html"><a href="statistical-models.html#marginal-effects"><i class="fa fa-check"></i><b>6.4.1</b> Marginal effects<span></span></a></li>
<li class="chapter" data-level="6.4.2" data-path="statistical-models.html"><a href="statistical-models.html#explainability-of-black-box-models"><i class="fa fa-check"></i><b>6.4.2</b> Explainability of <em>black-box</em> models<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="statistical-models.html"><a href="statistical-models.html#comparing-models"><i class="fa fa-check"></i><b>6.5</b> Comparing models<span></span></a></li>
<li class="chapter" data-level="6.6" data-path="statistical-models.html"><a href="statistical-models.html#using-a-model-for-prediction"><i class="fa fa-check"></i><b>6.6</b> Using a model for prediction<span></span></a></li>
<li class="chapter" data-level="6.7" data-path="statistical-models.html"><a href="statistical-models.html#beyond-linear-regression"><i class="fa fa-check"></i><b>6.7</b> Beyond linear regression<span></span></a></li>
<li class="chapter" data-level="6.8" data-path="statistical-models.html"><a href="statistical-models.html#hyper-parameters"><i class="fa fa-check"></i><b>6.8</b> Hyper-parameters<span></span></a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="statistical-models.html"><a href="statistical-models.html#ridge-regression"><i class="fa fa-check"></i><b>6.8.1</b> Ridge regression<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="statistical-models.html"><a href="statistical-models.html#training-validating-and-testing-models"><i class="fa fa-check"></i><b>6.9</b> Training, validating, and testing models<span></span></a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="statistical-models.html"><a href="statistical-models.html#set-up"><i class="fa fa-check"></i><b>6.9.1</b> Set up<span></span></a></li>
<li class="chapter" data-level="6.9.2" data-path="statistical-models.html"><a href="statistical-models.html#bayesian-hyperparameter-optimization"><i class="fa fa-check"></i><b>6.9.2</b> Bayesian hyperparameter optimization<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html"><i class="fa fa-check"></i><b>7</b> Defining your own functions<span></span></a>
<ul>
<li class="chapter" data-level="7.1" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#control-flow"><i class="fa fa-check"></i><b>7.1</b> Control flow<span></span></a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#if-else"><i class="fa fa-check"></i><b>7.1.1</b> If-else<span></span></a></li>
<li class="chapter" data-level="7.1.2" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#for-loops"><i class="fa fa-check"></i><b>7.1.2</b> For loops<span></span></a></li>
<li class="chapter" data-level="7.1.3" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#while-loops"><i class="fa fa-check"></i><b>7.1.3</b> While loops<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#writing-your-own-functions"><i class="fa fa-check"></i><b>7.2</b> Writing your own functions<span></span></a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#declaring-functions-in-r"><i class="fa fa-check"></i><b>7.2.1</b> Declaring functions in R<span></span></a></li>
<li class="chapter" data-level="7.2.2" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#fibonacci-numbers"><i class="fa fa-check"></i><b>7.2.2</b> Fibonacci numbers<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#exercises-4"><i class="fa fa-check"></i><b>7.3</b> Exercises<span></span></a>
<ul>
<li><a href="defining-your-own-functions.html#exercise-1-4">Exercise 1<span></span></a></li>
<li><a href="defining-your-own-functions.html#exercise-2-2">Exercise 2<span></span></a></li>
<li><a href="defining-your-own-functions.html#exercise-3-2">Exercise 3<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#functions-that-take-functions-as-arguments-writing-your-own-higher-order-functions"><i class="fa fa-check"></i><b>7.4</b> Functions that take functions as arguments: writing your own higher-order functions<span></span></a></li>
<li class="chapter" data-level="7.5" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#functions-that-return-functions"><i class="fa fa-check"></i><b>7.5</b> Functions that return functions<span></span></a></li>
<li class="chapter" data-level="7.6" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#functions-that-take-columns-of-data-as-arguments"><i class="fa fa-check"></i><b>7.6</b> Functions that take columns of data as arguments<span></span></a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#the-enquo---approach"><i class="fa fa-check"></i><b>7.6.1</b> The <code>enquo() - !!()</code> approach<span></span></a></li>
<li class="chapter" data-level="7.6.2" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#curly-curly-a-simplified-approach-to-the-enquo-and-framework"><i class="fa fa-check"></i><b>7.6.2</b> Curly Curly, a simplified approach to the <code>enquo()</code> and <code>!!()</code> framework<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#functions-that-use-loops"><i class="fa fa-check"></i><b>7.7</b> Functions that use loops<span></span></a></li>
<li class="chapter" data-level="7.8" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#anonymous-functions"><i class="fa fa-check"></i><b>7.8</b> Anonymous functions<span></span></a></li>
<li class="chapter" data-level="7.9" data-path="defining-your-own-functions.html"><a href="defining-your-own-functions.html#exercises-5"><i class="fa fa-check"></i><b>7.9</b> Exercises<span></span></a>
<ul>
<li><a href="defining-your-own-functions.html#exercise-1-5">Exercise 1<span></span></a></li>
<li><a href="defining-your-own-functions.html#exercise-2-3">Exercise 2<span></span></a></li>
<li><a href="defining-your-own-functions.html#exercise-3-3">Exercise 3<span></span></a></li>
<li><a href="defining-your-own-functions.html#exercise-4-2">Exercise 4<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="functional-programming.html"><a href="functional-programming.html"><i class="fa fa-check"></i><b>8</b> Functional programming<span></span></a>
<ul>
<li class="chapter" data-level="8.1" data-path="functional-programming.html"><a href="functional-programming.html#function-definitions"><i class="fa fa-check"></i><b>8.1</b> Function definitions<span></span></a></li>
<li class="chapter" data-level="8.2" data-path="functional-programming.html"><a href="functional-programming.html#properties-of-functions"><i class="fa fa-check"></i><b>8.2</b> Properties of functions<span></span></a></li>
<li class="chapter" data-level="8.3" data-path="functional-programming.html"><a href="functional-programming.html#functional-programming-with-purrr"><i class="fa fa-check"></i><b>8.3</b> Functional programming with <code>{purrr}</code><span></span></a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="functional-programming.html"><a href="functional-programming.html#doing-away-with-loops-the-map-family-of-functions"><i class="fa fa-check"></i><b>8.3.1</b> Doing away with loops: the <code>map*()</code> family of functions<span></span></a></li>
<li class="chapter" data-level="8.3.2" data-path="functional-programming.html"><a href="functional-programming.html#reducing-with-purrr"><i class="fa fa-check"></i><b>8.3.2</b> Reducing with <code>purrr</code><span></span></a></li>
<li class="chapter" data-level="8.3.3" data-path="functional-programming.html"><a href="functional-programming.html#error-handling-with-safely-and-possibly"><i class="fa fa-check"></i><b>8.3.3</b> Error handling with <code>safely()</code> and <code>possibly()</code><span></span></a></li>
<li class="chapter" data-level="8.3.4" data-path="functional-programming.html"><a href="functional-programming.html#partial-applications-with-partial"><i class="fa fa-check"></i><b>8.3.4</b> Partial applications with <code>partial()</code><span></span></a></li>
<li class="chapter" data-level="8.3.5" data-path="functional-programming.html"><a href="functional-programming.html#function-composition-using-compose"><i class="fa fa-check"></i><b>8.3.5</b> Function composition using <code>compose</code><span></span></a></li>
<li class="chapter" data-level="8.3.6" data-path="functional-programming.html"><a href="functional-programming.html#transposing-lists"><i class="fa fa-check"></i><b>8.3.6</b> «Transposing lists»<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="functional-programming.html"><a href="functional-programming.html#list-based-workflows-for-efficiency"><i class="fa fa-check"></i><b>8.4</b> List-based workflows for efficiency<span></span></a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="functional-programming.html"><a href="functional-programming.html#functional-programming-and-plotting"><i class="fa fa-check"></i><b>8.4.1</b> Functional programming and plotting<span></span></a></li>
<li class="chapter" data-level="8.4.2" data-path="functional-programming.html"><a href="functional-programming.html#modeling-with-functional-programming"><i class="fa fa-check"></i><b>8.4.2</b> Modeling with functional programming<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="functional-programming.html"><a href="functional-programming.html#exercises-6"><i class="fa fa-check"></i><b>8.5</b> Exercises<span></span></a>
<ul>
<li><a href="functional-programming.html#exercise-1-6">Exercise 1<span></span></a></li>
<li><a href="functional-programming.html#exercise-2-4">Exercise 2<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="package-development.html"><a href="package-development.html"><i class="fa fa-check"></i><b>9</b> Package development<span></span></a>
<ul>
<li class="chapter" data-level="9.1" data-path="package-development.html"><a href="package-development.html#why-you-need-to-write-your-own-package"><i class="fa fa-check"></i><b>9.1</b> Why you need to write your own package<span></span></a></li>
<li class="chapter" data-level="9.2" data-path="package-development.html"><a href="package-development.html#starting-easy-creating-a-package-to-share-data"><i class="fa fa-check"></i><b>9.2</b> Starting easy: creating a package to share data<span></span></a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="package-development.html"><a href="package-development.html#setting-up-a-github-account"><i class="fa fa-check"></i><b>9.2.1</b> Setting up a Github account<span></span></a></li>
<li class="chapter" data-level="9.2.2" data-path="package-development.html"><a href="package-development.html#starting-your-package"><i class="fa fa-check"></i><b>9.2.2</b> Starting your package<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="package-development.html"><a href="package-development.html#including-data-inside-the-package"><i class="fa fa-check"></i><b>9.3</b> Including data inside the package<span></span></a></li>
<li class="chapter" data-level="9.4" data-path="package-development.html"><a href="package-development.html#adding-functions-to-your-package"><i class="fa fa-check"></i><b>9.4</b> Adding functions to your package<span></span></a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="package-development.html"><a href="package-development.html#one-function-inside-one-script"><i class="fa fa-check"></i><b>9.4.1</b> One function inside one script<span></span></a></li>
<li class="chapter" data-level="9.4.2" data-path="package-development.html"><a href="package-development.html#many-functions-inside-a-script"><i class="fa fa-check"></i><b>9.4.2</b> Many functions inside a script<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="package-development.html"><a href="package-development.html#documenting-your-package"><i class="fa fa-check"></i><b>9.5</b> Documenting your package<span></span></a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="package-development.html"><a href="package-development.html#description"><i class="fa fa-check"></i><b>9.5.1</b> Description<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="package-development.html"><a href="package-development.html#unit-testing-your-package"><i class="fa fa-check"></i><b>9.6</b> Unit testing your package<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="further-topics.html"><a href="further-topics.html"><i class="fa fa-check"></i><b>10</b> Further topics<span></span></a>
<ul>
<li class="chapter" data-level="10.1" data-path="further-topics.html"><a href="further-topics.html#using-python-from-r-with-reticulate"><i class="fa fa-check"></i><b>10.1</b> Using Python from R with <code>{reticulate}</code><span></span></a></li>
<li class="chapter" data-level="10.2" data-path="further-topics.html"><a href="further-topics.html#generating-pdf-or-word-reports-with-r"><i class="fa fa-check"></i><b>10.2</b> Generating Pdf or Word reports with R<span></span></a></li>
<li class="chapter" data-level="10.3" data-path="further-topics.html"><a href="further-topics.html#scraping-the-internet"><i class="fa fa-check"></i><b>10.3</b> Scraping the internet<span></span></a></li>
<li class="chapter" data-level="10.4" data-path="further-topics.html"><a href="further-topics.html#regular-expressions"><i class="fa fa-check"></i><b>10.4</b> Regular expressions<span></span></a></li>
<li class="chapter" data-level="10.5" data-path="further-topics.html"><a href="further-topics.html#setting-up-a-blog-with-blogdown"><i class="fa fa-check"></i><b>10.5</b> Setting up a blog with <code>{blogdown}</code><span></span></a></li>
</ul></li>
<li><a href="references.html#references">References<span></span></a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modern R with the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="statistical-models" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Chapter 6</span> Statistical models<a href="statistical-models.html#statistical-models" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this chapter, we will not learn about all the models out there that you may or may not need.
Instead, I will show you how can use what you have learned until now and how you can apply these
concepts to modeling. Also, as you read in the beginning of the book, R has many many packages. So
the model you need is most probably already implemented in some package and you will very likely
not need to write your own from scratch.</p>
<p>In the first section, I will discuss the terminology used in this book. Then I will discuss
linear regression; showing how linear regression works illsutrates very well how other models
work too, without loss of generality. Then I will introduce the concepte of hyper-parameters
with ridge regression. This chapter will then finish with an introduction to cross-validation as
a way to tune the hyper-parameters of models that features them.</p>
<div id="terminology" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Terminology<a href="statistical-models.html#terminology" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Before continuing discussing about statistical models and model fitting it is worthwhile to discuss
terminology a little bit. Depending on your background, you might call an explanatory variable a
feature or the dependent variable the target. These are the same objects. The matrix of features
is usually called a design matrix, and what statisticians call the intercept is what
machine learning engineers call the bias. Referring to the intercept by bias is unfortunate, as bias
also has a very different meaning; bias is also what we call the error in a model that may cause
<em>biased</em> estimates. To finish up, the estimated parameters of the model may be called coefficients
or weights. Here again, I don’t like the using <em>weight</em> as weight as a very different meaning in
statistics.
So, in the remainder of this chapter, and book, I will use the terminology from the statistical
litterature, using dependent and explanatory variables (<code>y</code> and <code>x</code>), and calling the
estimated parameters coefficients and the intercept… well the intercept (the <span class="math inline">\(\beta\)</span>s of the model).
However, I will talk of <em>training</em> a model, instead of <em>estimating</em> a model.</p>
</div>
<div id="fitting-a-model-to-data" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Fitting a model to data<a href="statistical-models.html#fitting-a-model-to-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose you have a variable <code>y</code> that you wish to explain using a set of other variables <code>x1</code>, <code>x2</code>,
<code>x3</code>, etc. Let’s take a look at the <code>Housing</code> dataset from the <code>Ecdat</code> package:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="statistical-models.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Ecdat)</span>
<span id="cb1-2"><a href="statistical-models.html#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="statistical-models.html#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Housing)</span></code></pre></div>
<p>You can read a description of the dataset by running:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="statistical-models.html#cb2-1" aria-hidden="true" tabindex="-1"></a>?Housing</span></code></pre></div>
<pre><code>Housing                 package:Ecdat                  R Documentation

Sales Prices of Houses in the City of Windsor

Description:

     a cross-section from 1987

     _number of observations_ : 546

     _observation_ : goods

     _country_ : Canada

Usage:

     data(Housing)

Format:

     A dataframe containing :

     price: sale price of a house

     lotsize: the lot size of a property in square feet

     bedrooms: number of bedrooms

     bathrms: number of full bathrooms

     stories: number of stories excluding basement

     driveway: does the house has a driveway ?

     recroom: does the house has a recreational room ?

     fullbase: does the house has a full finished basement ?

     gashw: does the house uses gas for hot water heating ?

     airco: does the house has central air conditioning ?

     garagepl: number of garage places

     prefarea: is the house located in the preferred neighbourhood of the city ?

Source:

     Anglin, P.M.  and R.  Gencay (1996) “Semiparametric estimation of
     a hedonic price function”, _Journal of Applied Econometrics_,
     *11(6)*, 633-648.

References:

     Verbeek, Marno (2004) _A Guide to Modern Econometrics_, John Wiley
     and Sons, chapter 3.

     Journal of Applied Econometrics data archive : &lt;URL:
     http://qed.econ.queensu.ca/jae/&gt;.

See Also:

     ‘Index.Source’, ‘Index.Economics’, ‘Index.Econometrics’,
     ‘Index.Observations’</code></pre>
<p>or by looking for <code>Housing</code> in the help pane of RStudio. Usually, you would take a look a the data
before doing any modeling:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="statistical-models.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(Housing)</span></code></pre></div>
<pre><code>## Rows: 546
## Columns: 12
## $ price    &lt;dbl&gt; 42000, 38500, 49500, 60500, 61000, 66000, 66000, 69000, 83800…
## $ lotsize  &lt;dbl&gt; 5850, 4000, 3060, 6650, 6360, 4160, 3880, 4160, 4800, 5500, 7…
## $ bedrooms &lt;dbl&gt; 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 4, 1, 2, 3…
## $ bathrms  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1…
## $ stories  &lt;dbl&gt; 2, 1, 1, 2, 1, 1, 2, 3, 1, 4, 1, 1, 2, 1, 1, 1, 2, 3, 1, 1, 2…
## $ driveway &lt;fct&gt; yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, no, ye…
## $ recroom  &lt;fct&gt; no, no, no, yes, no, yes, no, no, yes, yes, no, no, no, no, n…
## $ fullbase &lt;fct&gt; yes, no, no, no, no, yes, yes, no, yes, no, yes, no, no, no, …
## $ gashw    &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…
## $ airco    &lt;fct&gt; no, no, no, no, no, yes, no, no, no, yes, yes, no, no, no, no…
## $ garagepl &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 2, 0, 0, 1, 3, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1…
## $ prefarea &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…</code></pre>
<p>Housing prices depend on a set of variables such as the number of bedrooms, the area it is located
and so on. If you believe that housing prices depend linearly on a set of explanatory variables,
you will want to estimate a linear model. To estimate a <em>linear model</em>, you will need to use the
built-in <code>lm()</code> function:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="statistical-models.html#cb6-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(price <span class="sc">~</span> lotsize <span class="sc">+</span> bedrooms, <span class="at">data =</span> Housing)</span></code></pre></div>
<p><code>lm()</code> takes a formula as an argument, which defines the model you want to estimate. In this case,
I ran the following regression:</p>
<p><span class="math display">\[
\text{price} = \beta_0 + \beta_1 * \text{lotsize} + \beta_2 * \text{bedrooms} + \varepsilon
\]</span></p>
<p>where <span class="math inline">\(\beta_0, \beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> are three parameters to estimate. To take a look at the
results, you can use the <code>summary()</code> method (not to be confused with <code>dplyr::summarise()</code>):</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="statistical-models.html#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = price ~ lotsize + bedrooms, data = Housing)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -65665 -12498  -2075   8970  97205 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 5.613e+03  4.103e+03   1.368    0.172    
## lotsize     6.053e+00  4.243e-01  14.265  &lt; 2e-16 ***
## bedrooms    1.057e+04  1.248e+03   8.470 2.31e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 21230 on 543 degrees of freedom
## Multiple R-squared:  0.3703, Adjusted R-squared:  0.3679 
## F-statistic: 159.6 on 2 and 543 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>if you wish to remove the intercept (<span class="math inline">\(\beta_0\)</span> in the above equation) from your model, you can
do so with <code>-1</code>:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="statistical-models.html#cb9-1" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(price <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span> lotsize <span class="sc">+</span> bedrooms, <span class="at">data =</span> Housing)</span>
<span id="cb9-2"><a href="statistical-models.html#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="statistical-models.html#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = price ~ -1 + lotsize + bedrooms, data = Housing)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -67229 -12342  -1333   9627  95509 
## 
## Coefficients:
##           Estimate Std. Error t value Pr(&gt;|t|)    
## lotsize      6.283      0.390   16.11   &lt;2e-16 ***
## bedrooms 11968.362    713.194   16.78   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 21250 on 544 degrees of freedom
## Multiple R-squared:  0.916,  Adjusted R-squared:  0.9157 
## F-statistic:  2965 on 2 and 544 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>or if you want to use all the columns inside <code>Housing</code>, replacing the column names by <code>.</code>:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="statistical-models.html#cb11-1" aria-hidden="true" tabindex="-1"></a>model3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(price <span class="sc">~</span> ., <span class="at">data =</span> Housing)</span>
<span id="cb11-2"><a href="statistical-models.html#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="statistical-models.html#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = price ~ ., data = Housing)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -41389  -9307   -591   7353  74875 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -4038.3504  3409.4713  -1.184 0.236762    
## lotsize         3.5463     0.3503  10.124  &lt; 2e-16 ***
## bedrooms     1832.0035  1047.0002   1.750 0.080733 .  
## bathrms     14335.5585  1489.9209   9.622  &lt; 2e-16 ***
## stories      6556.9457   925.2899   7.086 4.37e-12 ***
## drivewayyes  6687.7789  2045.2458   3.270 0.001145 ** 
## recroomyes   4511.2838  1899.9577   2.374 0.017929 *  
## fullbaseyes  5452.3855  1588.0239   3.433 0.000642 ***
## gashwyes    12831.4063  3217.5971   3.988 7.60e-05 ***
## aircoyes    12632.8904  1555.0211   8.124 3.15e-15 ***
## garagepl     4244.8290   840.5442   5.050 6.07e-07 ***
## prefareayes  9369.5132  1669.0907   5.614 3.19e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 15420 on 534 degrees of freedom
## Multiple R-squared:  0.6731, Adjusted R-squared:  0.6664 
## F-statistic: 99.97 on 11 and 534 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>You can access different elements of <code>model3</code> with <code>$</code>, because the result of <code>lm()</code> is a list
(you can check this claim with <code>typeof(model3)</code>:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="statistical-models.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(model3<span class="sc">$</span>coefficients)</span></code></pre></div>
<pre><code>##  (Intercept)      lotsize     bedrooms      bathrms      stories  drivewayyes 
## -4038.350425     3.546303  1832.003466 14335.558468  6556.945711  6687.778890 
##   recroomyes  fullbaseyes     gashwyes     aircoyes     garagepl  prefareayes 
##  4511.283826  5452.385539 12831.406266 12632.890405  4244.829004  9369.513239</code></pre>
<p>but I prefer to use the <code>{broom}</code> package, and more specifically the <code>tidy()</code> function, which
converts <code>model3</code> into a neat <code>data.frame</code>:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="statistical-models.html#cb15-1" aria-hidden="true" tabindex="-1"></a>results3 <span class="ot">&lt;-</span> broom<span class="sc">::</span><span class="fu">tidy</span>(model3)</span>
<span id="cb15-2"><a href="statistical-models.html#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="statistical-models.html#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(results3)</span></code></pre></div>
<pre><code>## Rows: 12
## Columns: 5
## $ term      &lt;chr&gt; &quot;(Intercept)&quot;, &quot;lotsize&quot;, &quot;bedrooms&quot;, &quot;bathrms&quot;, &quot;stories&quot;, …
## $ estimate  &lt;dbl&gt; -4038.350425, 3.546303, 1832.003466, 14335.558468, 6556.9457…
## $ std.error &lt;dbl&gt; 3409.4713, 0.3503, 1047.0002, 1489.9209, 925.2899, 2045.2458…
## $ statistic &lt;dbl&gt; -1.184451, 10.123618, 1.749764, 9.621691, 7.086369, 3.269914…
## $ p.value   &lt;dbl&gt; 2.367616e-01, 3.732442e-22, 8.073341e-02, 2.570369e-20, 4.37…</code></pre>
<p>I explicitely write <code>broom::tidy()</code> because <code>tidy()</code> is a popular function name. For instance,
it is also a function from the <code>{yardstick}</code> package, which does not do the same thing at all. Since
I will also be using <code>{yardstick}</code> I prefer to explicitely write <code>broom::tidy()</code> to avoid conflicts.</p>
<p>Using <code>broom::tidy()</code> is useful, because you can then work on the results easily, for example if
you wish to only keep results that are significant at the 5% level:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="statistical-models.html#cb17-1" aria-hidden="true" tabindex="-1"></a>results3 <span class="sc">%&gt;%</span></span>
<span id="cb17-2"><a href="statistical-models.html#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(p.value <span class="sc">&lt;</span> <span class="fl">0.05</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 × 5
##    term        estimate std.error statistic  p.value
##    &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 lotsize         3.55     0.350     10.1  3.73e-22
##  2 bathrms     14336.    1490.         9.62 2.57e-20
##  3 stories      6557.     925.         7.09 4.37e-12
##  4 drivewayyes  6688.    2045.         3.27 1.15e- 3
##  5 recroomyes   4511.    1900.         2.37 1.79e- 2
##  6 fullbaseyes  5452.    1588.         3.43 6.42e- 4
##  7 gashwyes    12831.    3218.         3.99 7.60e- 5
##  8 aircoyes    12633.    1555.         8.12 3.15e-15
##  9 garagepl     4245.     841.         5.05 6.07e- 7
## 10 prefareayes  9370.    1669.         5.61 3.19e- 8</code></pre>
<p>You can even add new columns, such as the confidence intervals:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="statistical-models.html#cb19-1" aria-hidden="true" tabindex="-1"></a>results3 <span class="ot">&lt;-</span> broom<span class="sc">::</span><span class="fu">tidy</span>(model3, <span class="at">conf.int =</span> <span class="cn">TRUE</span>, <span class="at">conf.level =</span> <span class="fl">0.95</span>)</span>
<span id="cb19-2"><a href="statistical-models.html#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="statistical-models.html#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(results3)</span></code></pre></div>
<pre><code>## # A tibble: 12 × 7
##    term        estimate std.error statistic  p.value  conf.low conf.high
##    &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1 (Intercept) -4038.    3409.        -1.18 2.37e- 1 -10736.     2659.  
##  2 lotsize         3.55     0.350     10.1  3.73e-22      2.86      4.23
##  3 bedrooms     1832.    1047.         1.75 8.07e- 2   -225.     3889.  
##  4 bathrms     14336.    1490.         9.62 2.57e-20  11409.    17262.  
##  5 stories      6557.     925.         7.09 4.37e-12   4739.     8375.  
##  6 drivewayyes  6688.    2045.         3.27 1.15e- 3   2670.    10705.  
##  7 recroomyes   4511.    1900.         2.37 1.79e- 2    779.     8244.  
##  8 fullbaseyes  5452.    1588.         3.43 6.42e- 4   2333.     8572.  
##  9 gashwyes    12831.    3218.         3.99 7.60e- 5   6511.    19152.  
## 10 aircoyes    12633.    1555.         8.12 3.15e-15   9578.    15688.  
## 11 garagepl     4245.     841.         5.05 6.07e- 7   2594.     5896.  
## 12 prefareayes  9370.    1669.         5.61 3.19e- 8   6091.    12648.</code></pre>
<p>Going back to model estimation, you can of course use <code>lm()</code> in a pipe workflow:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="statistical-models.html#cb21-1" aria-hidden="true" tabindex="-1"></a>Housing <span class="sc">%&gt;%</span></span>
<span id="cb21-2"><a href="statistical-models.html#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>driveway, <span class="sc">-</span>stories) <span class="sc">%&gt;%</span></span>
<span id="cb21-3"><a href="statistical-models.html#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lm</span>(price <span class="sc">~</span> ., <span class="at">data =</span> .) <span class="sc">%&gt;%</span></span>
<span id="cb21-4"><a href="statistical-models.html#cb21-4" aria-hidden="true" tabindex="-1"></a>  broom<span class="sc">::</span><span class="fu">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 10 × 5
##    term        estimate std.error statistic  p.value
##    &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 (Intercept)  3025.    3263.        0.927 3.54e- 1
##  2 lotsize         3.67     0.363    10.1   4.52e-22
##  3 bedrooms     4140.    1036.        3.99  7.38e- 5
##  4 bathrms     16443.    1546.       10.6   4.29e-24
##  5 recroomyes   5660.    2010.        2.82  5.05e- 3
##  6 fullbaseyes  2241.    1618.        1.38  1.67e- 1
##  7 gashwyes    13568.    3411.        3.98  7.93e- 5
##  8 aircoyes    15578.    1597.        9.75  8.53e-21
##  9 garagepl     4232.     883.        4.79  2.12e- 6
## 10 prefareayes 10729.    1753.        6.12  1.81e- 9</code></pre>
<p>The first <code>.</code> in the <code>lm()</code> function is used to indicate that we wish to use all the data from <code>Housing</code>
(minus <code>driveway</code> and <code>stories</code> which I removed using <code>select()</code> and the <code>-</code> sign), and the second <code>.</code> is
used to <em>place</em> the result from the two <code>dplyr</code> instructions that preceded is to be placed there.
The picture below should help you understand:</p>
<p><img src="pics/pipe_to_second_position.png" width="288" /></p>
<p>You have to specify this, because by default, when using <code>%&gt;%</code> the left hand side argument gets
passed as the first argument of the function on the right hand side.</p>
<p>Since version 4.2, R now also natively includes a placeholder, <code>_</code>:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="statistical-models.html#cb23-1" aria-hidden="true" tabindex="-1"></a>Housing <span class="sc">|&gt;</span></span>
<span id="cb23-2"><a href="statistical-models.html#cb23-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>driveway, <span class="sc">-</span>stories) <span class="sc">|&gt;</span></span>
<span id="cb23-3"><a href="statistical-models.html#cb23-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lm</span>(price <span class="sc">~</span> ., <span class="at">data =</span> _) <span class="sc">|&gt;</span></span>
<span id="cb23-4"><a href="statistical-models.html#cb23-4" aria-hidden="true" tabindex="-1"></a>  broom<span class="sc">::</span><span class="fu">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 10 × 5
##    term        estimate std.error statistic  p.value
##    &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 (Intercept)  3025.    3263.        0.927 3.54e- 1
##  2 lotsize         3.67     0.363    10.1   4.52e-22
##  3 bedrooms     4140.    1036.        3.99  7.38e- 5
##  4 bathrms     16443.    1546.       10.6   4.29e-24
##  5 recroomyes   5660.    2010.        2.82  5.05e- 3
##  6 fullbaseyes  2241.    1618.        1.38  1.67e- 1
##  7 gashwyes    13568.    3411.        3.98  7.93e- 5
##  8 aircoyes    15578.    1597.        9.75  8.53e-21
##  9 garagepl     4232.     883.        4.79  2.12e- 6
## 10 prefareayes 10729.    1753.        6.12  1.81e- 9</code></pre>
<p>For the example above, I’ve also switched from <code>%&gt;%</code> to <code>|&gt;</code>, or else I can’t use the <code>_</code> placeholder.
The advantage of the <code>_</code> placeholder is that it disambiguates <code>.</code>. So here, the <code>.</code> is a placeholder for
all the variables in the dataset, and <code>_</code> is a placeholder for the dataset.</p>
</div>
<div id="diagnostics" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Diagnostics<a href="statistical-models.html#diagnostics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Diagnostics are useful metrics to assess model fit. You can read some of these diagnostics, such as
the <span class="math inline">\(R^2\)</span> at the bottom of the summary (when running <code>summary(my_model)</code>), but if you want to do
more than simply reading these diagnostics from RStudio, you can put those in a <code>data.frame</code> too,
using <code>broom::glance()</code>:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="statistical-models.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(model3)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared  sigma statistic   p.value    df logLik    AIC    BIC
##       &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1     0.673         0.666 15423.      100. 6.18e-122    11 -6034. 12094. 12150.
## # … with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<p>You can also plot the usual diagnostics plots using <code>ggfortify::autoplot()</code> which uses the
<code>{ggplot2}</code> package under the hood:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="statistical-models.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggfortify)</span>
<span id="cb27-2"><a href="statistical-models.html#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="statistical-models.html#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(model3, <span class="at">which =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>) <span class="sc">+</span> <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="modern_R_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p><code>which=1:6</code> is an additional option that shows you all the diagnostics plot. If you omit this
option, you will only get 4 of them.</p>
<p>You can also get the residuals of the regression in two ways; either you grab them directly from
the model fit:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="statistical-models.html#cb28-1" aria-hidden="true" tabindex="-1"></a>resi3 <span class="ot">&lt;-</span> <span class="fu">residuals</span>(model3)</span></code></pre></div>
<p>or you can augment the original data with a residuals column, using <code>broom::augment()</code>:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="statistical-models.html#cb29-1" aria-hidden="true" tabindex="-1"></a>housing_aug <span class="ot">&lt;-</span> <span class="fu">augment</span>(model3)</span></code></pre></div>
<p>Let’s take a look at <code>housing_aug</code>:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="statistical-models.html#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(housing_aug)</span></code></pre></div>
<pre><code>## Rows: 546
## Columns: 18
## $ price      &lt;dbl&gt; 42000, 38500, 49500, 60500, 61000, 66000, 66000, 69000, 838…
## $ lotsize    &lt;dbl&gt; 5850, 4000, 3060, 6650, 6360, 4160, 3880, 4160, 4800, 5500,…
## $ bedrooms   &lt;dbl&gt; 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 4, 1, 2,…
## $ bathrms    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2,…
## $ stories    &lt;dbl&gt; 2, 1, 1, 2, 1, 1, 2, 3, 1, 4, 1, 1, 2, 1, 1, 1, 2, 3, 1, 1,…
## $ driveway   &lt;fct&gt; yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, no, …
## $ recroom    &lt;fct&gt; no, no, no, yes, no, yes, no, no, yes, yes, no, no, no, no,…
## $ fullbase   &lt;fct&gt; yes, no, no, no, no, yes, yes, no, yes, no, yes, no, no, no…
## $ gashw      &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,…
## $ airco      &lt;fct&gt; no, no, no, no, no, yes, no, no, no, yes, yes, no, no, no, …
## $ garagepl   &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 2, 0, 0, 1, 3, 0, 0, 0, 0, 0, 1, 0, 0, 1,…
## $ prefarea   &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,…
## $ .fitted    &lt;dbl&gt; 66037.98, 41391.15, 39889.63, 63689.09, 49760.43, 66387.12,…
## $ .resid     &lt;dbl&gt; -24037.9757, -2891.1515, 9610.3699, -3189.0873, 11239.5735,…
## $ .hat       &lt;dbl&gt; 0.013477335, 0.008316321, 0.009893730, 0.021510891, 0.01033…
## $ .sigma     &lt;dbl&gt; 15402.01, 15437.14, 15431.98, 15437.02, 15429.89, 15437.64,…
## $ .cooksd    &lt;dbl&gt; 2.803214e-03, 2.476265e-05, 3.265481e-04, 8.004787e-05, 4.6…
## $ .std.resid &lt;dbl&gt; -1.56917096, -0.18823924, 0.62621736, -0.20903274, 0.732539…</code></pre>
<p>A few columns have been added to the original data, among them <code>.resid</code> which contains the
residuals. Let’s plot them:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="statistical-models.html#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(housing_aug) <span class="sc">+</span></span>
<span id="cb32-2"><a href="statistical-models.html#cb32-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(.resid))</span></code></pre></div>
<p><img src="modern_R_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>Fitted values are also added to the original data, under the variable <code>.fitted</code>. It would also have
been possible to get the fitted values with:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="statistical-models.html#cb33-1" aria-hidden="true" tabindex="-1"></a>fit3 <span class="ot">&lt;-</span> <span class="fu">fitted</span>(model3)</span></code></pre></div>
<p>but I prefer using <code>augment()</code>, because the columns get merged to the original data, which then
makes it easier to find specific individuals, for example, you might want to know for which housing
units the model underestimates the price:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="statistical-models.html#cb34-1" aria-hidden="true" tabindex="-1"></a>total_pos <span class="ot">&lt;-</span> housing_aug <span class="sc">%&gt;%</span></span>
<span id="cb34-2"><a href="statistical-models.html#cb34-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(.resid <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb34-3"><a href="statistical-models.html#cb34-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">total =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb34-4"><a href="statistical-models.html#cb34-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(total)</span></code></pre></div>
<p>we find 261 individuals where the residuals are positive. It is also easier to
extract outliers:</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="statistical-models.html#cb35-1" aria-hidden="true" tabindex="-1"></a>housing_aug <span class="sc">%&gt;%</span></span>
<span id="cb35-2"><a href="statistical-models.html#cb35-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">prank =</span> <span class="fu">cume_dist</span>(.cooksd)) <span class="sc">%&gt;%</span></span>
<span id="cb35-3"><a href="statistical-models.html#cb35-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(prank <span class="sc">&gt;</span> <span class="fl">0.99</span>) <span class="sc">%&gt;%</span></span>
<span id="cb35-4"><a href="statistical-models.html#cb35-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glimpse</span>()</span></code></pre></div>
<pre><code>## Rows: 6
## Columns: 19
## $ price      &lt;dbl&gt; 163000, 125000, 132000, 175000, 190000, 174500
## $ lotsize    &lt;dbl&gt; 7420, 4320, 3500, 9960, 7420, 7500
## $ bedrooms   &lt;dbl&gt; 4, 3, 4, 3, 4, 4
## $ bathrms    &lt;dbl&gt; 1, 1, 2, 2, 2, 2
## $ stories    &lt;dbl&gt; 2, 2, 2, 2, 3, 2
## $ driveway   &lt;fct&gt; yes, yes, yes, yes, yes, yes
## $ recroom    &lt;fct&gt; yes, no, no, no, no, no
## $ fullbase   &lt;fct&gt; yes, yes, no, yes, no, yes
## $ gashw      &lt;fct&gt; no, yes, yes, no, no, no
## $ airco      &lt;fct&gt; yes, no, no, no, yes, yes
## $ garagepl   &lt;dbl&gt; 2, 2, 2, 2, 2, 3
## $ prefarea   &lt;fct&gt; no, no, no, yes, yes, yes
## $ .fitted    &lt;dbl&gt; 94826.68, 77688.37, 85495.58, 108563.18, 115125.03, 118549.…
## $ .resid     &lt;dbl&gt; 68173.32, 47311.63, 46504.42, 66436.82, 74874.97, 55951.00
## $ .hat       &lt;dbl&gt; 0.02671105, 0.05303793, 0.05282929, 0.02819317, 0.02008141,…
## $ .sigma     &lt;dbl&gt; 15144.70, 15293.34, 15298.27, 15159.14, 15085.99, 15240.66
## $ .cooksd    &lt;dbl&gt; 0.04590995, 0.04637969, 0.04461464, 0.04616068, 0.04107317,…
## $ .std.resid &lt;dbl&gt; 4.480428, 3.152300, 3.098176, 4.369631, 4.904193, 3.679815
## $ prank      &lt;dbl&gt; 0.9963370, 1.0000000, 0.9945055, 0.9981685, 0.9926740, 0.99…</code></pre>
<p><code>prank</code> is a variable I created with <code>cume_dist()</code> which is a <code>dplyr</code> function that returns the
proportion of all values less than or equal to the current rank. For example:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="statistical-models.html#cb37-1" aria-hidden="true" tabindex="-1"></a>example <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="fl">4.6</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="fl">0.8</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb37-2"><a href="statistical-models.html#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cume_dist</span>(example)</span></code></pre></div>
<pre><code>## [1] 1.0000000 0.8571429 0.7142857 0.5714286 0.4285714 0.2857143 0.1428571</code></pre>
<p>by filtering <code>prank &gt; 0.99</code> we get the top 1% of outliers according to Cook’s distance.</p>
</div>
<div id="interpreting-models" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Interpreting models<a href="statistical-models.html#interpreting-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Model interpretation is essential in the social sciences, but it is also getting very important
in machine learning. As usual, the terminology is different; in machine learning, we speak about
explainability. There is a very important aspect that one has to understand when it comes to
interpretability/explainability: <em>classical, parametric</em> models, and <em>black-box</em> models. This
is very well explained in <span class="citation">Breiman (<a href="#ref-breiman2001" role="doc-biblioref">2001</a>)</span>, an absolute must read (link to paper, in PDF format:
<a href="https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726">click here</a>). The gist of the paper
is that there are two cultures of statistical modeling; one culture relies on modeling the data
generating process, for instance, by considering that a variable y (independent variable, or target)
is a linear combination of input variables x (dependent variables, or features) plus some noise. The
other culture uses complex algorithms (random forests, neural networks)
to model the relationship between y and x. The author argues that most statisticians have relied
for too long on modeling data generating processes and do not use all the potential offered by
these complex algorithms. I think that a lot of things have changed since then, and that nowadays
any practitioner that uses data is open to use any type of model or algorithm, as long as it does
the job. However, the paper is very interesting, and the discussion on trade-off between
simplicity of the model and interpretability/explainability is still relevant today.</p>
<p>In this section, I will explain how one can go about interpreting or explaining models from these
two cultures.</p>
<p>Also, it is important to note here that the discussion that will follow will be heavily influenced
by my econometrics background. I will focus on marginal effects as way to interpret parametric
models (models from the first culture described above), but depending on the field, practitioners
might use something else (for instance by computing odds ratios in a logistic regression).</p>
<p>I will start by interpretability of <em>classical</em> statistical models.</p>
<div id="marginal-effects" class="section level3 hasAnchor" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Marginal effects<a href="statistical-models.html#marginal-effects" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If one wants to know the effect of variable <code>x</code> on the dependent variable <code>y</code>,
so-called marginal effects have to be computed. This is easily done in R with the <code>{marginaleffects}</code> package.
Formally, marginal effects are the partial derivative of the regression equation with respect to the variable
we want to look at.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="statistical-models.html#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(marginaleffects)</span>
<span id="cb39-2"><a href="statistical-models.html#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="statistical-models.html#cb39-3" aria-hidden="true" tabindex="-1"></a>effects_model3 <span class="ot">&lt;-</span> <span class="fu">marginaleffects</span>(model3)</span>
<span id="cb39-4"><a href="statistical-models.html#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="statistical-models.html#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(effects_model3)</span></code></pre></div>
<pre><code>## Average marginal effects 
##        Term Contrast    Effect Std. Error z value   Pr(&gt;|z|)     2.5 %  97.5 %
## 1   lotsize    dY/dX     3.546     0.3846   9.220 &lt; 2.22e-16     2.792     4.3
## 2  bedrooms    dY/dX  1832.003  1047.1308   1.750 0.08019668  -220.335  3884.3
## 3   bathrms    dY/dX 14335.558  1489.8472   9.622 &lt; 2.22e-16 11415.512 17255.6
## 4   stories    dY/dX  6556.946   925.3293   7.086 1.3798e-12  4743.334  8370.6
## 5  driveway yes - no  6687.779  2045.2459   3.270 0.00107580  2679.171 10696.4
## 6   recroom yes - no  4511.284  1899.9577   2.374 0.01757689   787.435  8235.1
## 7  fullbase yes - no  5452.386  1588.0239   3.433 0.00059597  2339.916  8564.9
## 8     gashw yes - no 12831.406  3217.5970   3.988 6.6665e-05  6525.032 19137.8
## 9     airco yes - no 12632.890  1555.0211   8.124 4.4409e-16  9585.105 15680.7
## 10 garagepl    dY/dX  4244.829   840.8294   5.048 4.4556e-07  2596.834  5892.8
## 11 prefarea yes - no  9369.513  1669.0906   5.614 1.9822e-08  6098.156 12640.9
## 
## Model type:  lm 
## Prediction type:  response</code></pre>
<p>Let’s go through this: <code>summary(effects_model3)</code> shows the average marginal effects for each of the dependent
variables that were used in <code>model3</code>. The way to interpret them is as follows:
<em>everything else held constant (often you’ll read the Latin ceteris paribus for this), a unit increase in
<code>lotize</code> increases the <code>price</code> by 3.546 units, on average.</em>
The <em>everything held constant</em> part is crucial; with marginal effects, you’re looking at just the effect of
one variable at a time. For discrete variables, like <code>driveway</code>, this is simpler: imagine you have two
equal houses, exactly the same house, one has a driveway and the other doesn’t. The one with the driveway
is 6687 units more expensive, <em>on average</em>.</p>
<p>Now it turns out that in the case of a linear model, the average marginal effects are exactly equal to the
coefficients. Just compare <code>summary(model3)</code> to <code>effects_model3</code> to see
(and remember, I told you that marginal effects were the partial derivative of the regression equation with
respect to the variable of interest. So the derivative of <span class="math inline">\(\alpha*X_1 + ....\)</span> with respect to <span class="math inline">\(X_1\)</span> will
be <span class="math inline">\(\alpha\)</span>). But in the case of a more complex, non-linear model, this is not so obvious. This is
where <code>{marginaleffects}</code> will make your life much easier.</p>
<p>It is also possible to plot the results:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="statistical-models.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(effects_model3)</span></code></pre></div>
<p><img src="modern_R_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p><code>effects_model3</code> is a data frame containing the effects for each house in the data set. For example,
let’s take a look at the first house:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="statistical-models.html#cb42-1" aria-hidden="true" tabindex="-1"></a>effects_model3 <span class="sc">%&gt;%</span></span>
<span id="cb42-2"><a href="statistical-models.html#cb42-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(rowid <span class="sc">==</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>##    rowid     type     term contrast         dydx   std.error statistic
## 1      1 response  lotsize    dY/dX     3.546303    3.502482  1.012512
## 2      1 response bedrooms    dY/dX  1832.003466 1046.703475  1.750260
## 3      1 response  bathrms    dY/dX 14335.558468 1490.238577  9.619640
## 4      1 response  stories    dY/dX  6556.945711  926.374131  7.078075
## 5      1 response driveway yes - no  6687.778890 2045.246032  3.269914
## 6      1 response  recroom yes - no  4511.283826 1899.957718  2.374413
## 7      1 response fullbase yes - no  5452.385539 1588.023754  3.433441
## 8      1 response    gashw yes - no 12831.406266 3217.597193  3.987885
## 9      1 response    airco yes - no 12632.890405 1555.020704  8.123937
## 10     1 response garagepl    dY/dX  4244.829004  840.856005  5.048223
## 11     1 response prefarea yes - no  9369.513239 1669.090497  5.613544
##         p.value     conf.low   conf.high price lotsize bedrooms bathrms stories
## 1  3.112935e-01    -3.318435    10.41104 42000    5850        3       1       2
## 2  8.007342e-02  -219.497648  3883.50458 42000    5850        3       1       2
## 3  6.606203e-22 11414.744528 17256.37241 42000    5850        3       1       2
## 4  1.461705e-12  4741.285779  8372.60564 42000    5850        3       1       2
## 5  1.075801e-03  2679.170328 10696.38745 42000    5850        3       1       2
## 6  1.757689e-02   787.435126  8235.13253 42000    5850        3       1       2
## 7  5.959723e-04  2339.916175  8564.85490 42000    5850        3       1       2
## 8  6.666508e-05  6525.031651 19137.78088 42000    5850        3       1       2
## 9  4.512997e-16  9585.105829 15680.67498 42000    5850        3       1       2
## 10 4.459374e-07  2596.781519  5892.87649 42000    5850        3       1       2
## 11 1.982240e-08  6098.155978 12640.87050 42000    5850        3       1       2
##    driveway recroom fullbase gashw airco garagepl prefarea
## 1       yes      no      yes    no    no        1       no
## 2       yes      no      yes    no    no        1       no
## 3       yes      no      yes    no    no        1       no
## 4       yes      no      yes    no    no        1       no
## 5       yes      no      yes    no    no        1       no
## 6       yes      no      yes    no    no        1       no
## 7       yes      no      yes    no    no        1       no
## 8       yes      no      yes    no    no        1       no
## 9       yes      no      yes    no    no        1       no
## 10      yes      no      yes    no    no        1       no
## 11      yes      no      yes    no    no        1       no</code></pre>
<p><code>rowid</code> is column that identifies the houses in the original data set, so <code>rowid == 1</code> filters out
the first house. This shows you the marginal effects (column <code>dydx</code> computed for this house; but
remember, since we’re dealing with a linear model, the values of the marginal effects are constant.
If you don’t see the point of this discussion, don’t fret, the next example should make things
clearer.</p>
<p>Let’s estimate a logit model and compute the marginal effects. You might know logit models as
<em>logistic regression</em>. Logit models can be estimated using the <code>glm()</code> function, which stands for
generalized linear models.</p>
<p>As an example, we are going to use the <code>Participation</code> data, also from the <code>{Ecdat}</code> package:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="statistical-models.html#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Participation)</span></code></pre></div>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="statistical-models.html#cb45-1" aria-hidden="true" tabindex="-1"></a>?Particpation</span></code></pre></div>
<pre><code>Participation              package:Ecdat               R Documentation

Labor Force Participation

Description:

     a cross-section

     _number of observations_ : 872

     _observation_ : individuals

     _country_ : Switzerland

Usage:

     data(Participation)

Format:

     A dataframe containing :

     lfp labour force participation ?

     lnnlinc the log of nonlabour income

     age age in years divided by 10

     educ years of formal education

     nyc the number of young children (younger than 7)

     noc number of older children

     foreign foreigner ?

Source:

     Gerfin, Michael (1996) “Parametric and semiparametric estimation
     of the binary response”, _Journal of Applied Econometrics_,
     *11(3)*, 321-340.

References:

     Davidson, R.  and James G.  MacKinnon (2004) _Econometric Theory
     and Methods_, New York, Oxford University Press, &lt;URL:
     http://www.econ.queensu.ca/ETM/&gt;, chapter 11.

     Journal of Applied Econometrics data archive : &lt;URL:
     http://qed.econ.queensu.ca/jae/&gt;.

See Also:

     ‘Index.Source’, ‘Index.Economics’, ‘Index.Econometrics’,
     ‘Index.Observations’</code></pre>
<p>The variable of interest is <code>lfp</code>: whether the individual participates in the labour force or not.
To know which variables are relevant in the decision to participate in the labour force, one could
train a logit model, using <code>glm()</code>:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="statistical-models.html#cb47-1" aria-hidden="true" tabindex="-1"></a>logit_participation <span class="ot">&lt;-</span> <span class="fu">glm</span>(lfp <span class="sc">~</span> ., <span class="at">data =</span> Participation, <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb47-2"><a href="statistical-models.html#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="statistical-models.html#cb47-3" aria-hidden="true" tabindex="-1"></a>broom<span class="sc">::</span><span class="fu">tidy</span>(logit_participation)</span></code></pre></div>
<pre><code>## # A tibble: 7 × 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)  10.4       2.17       4.79  1.69e- 6
## 2 lnnlinc      -0.815     0.206     -3.97  7.31e- 5
## 3 age          -0.510     0.0905    -5.64  1.72e- 8
## 4 educ          0.0317    0.0290     1.09  2.75e- 1
## 5 nyc          -1.33      0.180     -7.39  1.51e-13
## 6 noc          -0.0220    0.0738    -0.298 7.66e- 1
## 7 foreignyes    1.31      0.200      6.56  5.38e-11</code></pre>
<p>From the results above, one can only interpret the sign of the coefficients. To know how much a
variable influences the labour force participation, one has to use <code>marginaleffects()</code>:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="statistical-models.html#cb49-1" aria-hidden="true" tabindex="-1"></a>effects_logit_participation <span class="ot">&lt;-</span> <span class="fu">marginaleffects</span>(logit_participation)</span>
<span id="cb49-2"><a href="statistical-models.html#cb49-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-3"><a href="statistical-models.html#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(effects_logit_participation)</span></code></pre></div>
<pre><code>## Average marginal effects 
##      Term Contrast    Effect Std. Error z value   Pr(&gt;|z|)     2.5 %   97.5 %
## 1 lnnlinc    dY/dX -0.169942   0.041511 -4.0939 4.2424e-05 -0.251303 -0.08858
## 2     age    dY/dX -0.106408   0.017591 -6.0491 1.4563e-09 -0.140885 -0.07193
## 3    educ    dY/dX  0.006616   0.006039  1.0954    0.27335 -0.005222  0.01845
## 4     nyc    dY/dX -0.277466   0.033255 -8.3435 &lt; 2.22e-16 -0.342645 -0.21229
## 5     noc    dY/dX -0.004584   0.015378 -0.2981    0.76563 -0.034725  0.02556
## 6 foreign yes - no  0.283377   0.039840  7.1129 1.1360e-12  0.205292  0.36146
## 
## Model type:  glm 
## Prediction type:  response</code></pre>
<p>As you can see, the average marginal effects here are not equal to the estimated coefficients of the
model. Let’s take a look at the first row of the data:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="statistical-models.html#cb51-1" aria-hidden="true" tabindex="-1"></a>Participation[<span class="dv">1</span>, ]</span></code></pre></div>
<pre><code>##   lfp lnnlinc age educ nyc noc foreign
## 1  no 10.7875   3    8   1   1      no</code></pre>
<p>and let’s now look at <code>rowid == 1</code> in the marginal effects data frame:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="statistical-models.html#cb53-1" aria-hidden="true" tabindex="-1"></a>effects_logit_participation <span class="sc">%&gt;%</span></span>
<span id="cb53-2"><a href="statistical-models.html#cb53-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(rowid <span class="sc">==</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>##   rowid     type    term contrast         dydx   std.error  statistic
## 1     1 response lnnlinc    dY/dX -0.156674613 0.038528914 -4.0664165
## 2     1 response     age    dY/dX -0.098100999 0.020124864 -4.8746168
## 3     1 response    educ    dY/dX  0.006099178 0.005366872  1.1364493
## 4     1 response     nyc    dY/dX -0.255800770 0.029371313 -8.7092044
## 5     1 response     noc    dY/dX -0.004226379 0.014167358 -0.2983181
## 6     1 response foreign yes - no  0.305630005 0.045174828  6.7654935
##        p.value     conf.low   conf.high lfp lnnlinc age educ nyc noc foreign
## 1 4.774158e-05 -0.232189897 -0.08115933  no 10.7875   3    8   1   1      no
## 2 1.090199e-06 -0.137545007 -0.05865699  no 10.7875   3    8   1   1      no
## 3 2.557686e-01 -0.004419697  0.01661805  no 10.7875   3    8   1   1      no
## 4 3.060149e-18 -0.313367486 -0.19823405  no 10.7875   3    8   1   1      no
## 5 7.654604e-01 -0.031993891  0.02354113  no 10.7875   3    8   1   1      no
## 6 1.328556e-11  0.217088969  0.39417104  no 10.7875   3    8   1   1      no</code></pre>
<p>Let’s focus on the first row, where <code>term</code> is <code>lnnlinc</code>. What we see here is the effect of an infinitesimal
increase in the variable <code>lnnlinc</code> on the participation, for an individual who has the following
characteristics: <code>lnnlinc = 10.7875</code>, <code>age = 3</code>, <code>educ = 8</code>, <code>nyc = 1</code>, <code>noc = 1</code> and <code>foreign = no</code>, which
are the characteristics of this first individual in our data.</p>
<p>So let’s look at the value of <code>dydx</code> for every individual:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="statistical-models.html#cb55-1" aria-hidden="true" tabindex="-1"></a>dydx_lnnlinc <span class="ot">&lt;-</span> effects_logit_participation <span class="sc">%&gt;%</span></span>
<span id="cb55-2"><a href="statistical-models.html#cb55-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(term <span class="sc">==</span> <span class="st">&quot;lnnlinc&quot;</span>)</span>
<span id="cb55-3"><a href="statistical-models.html#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="statistical-models.html#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dydx_lnnlinc)</span></code></pre></div>
<pre><code>##   rowid     type    term contrast        dydx  std.error statistic      p.value
## 1     1 response lnnlinc    dY/dX -0.15667461 0.03852891 -4.066416 4.774158e-05
## 2     2 response lnnlinc    dY/dX -0.20014394 0.05124728 -3.905455 9.404818e-05
## 3     3 response lnnlinc    dY/dX -0.18494891 0.04320270 -4.280957 1.860912e-05
## 4     4 response lnnlinc    dY/dX -0.05377069 0.01586793 -3.388640 7.024012e-04
## 5     5 response lnnlinc    dY/dX -0.18710270 0.04503463 -4.154640 3.257997e-05
## 6     6 response lnnlinc    dY/dX -0.19586843 0.04782532 -4.095496 4.212648e-05
##      conf.low   conf.high lfp  lnnlinc age educ nyc noc foreign
## 1 -0.23218990 -0.08115933  no 10.78750 3.0    8   1   1      no
## 2 -0.30058675 -0.09970112 yes 10.52425 4.5    8   0   1      no
## 3 -0.26962465 -0.10027317  no 10.96858 4.6    9   0   0      no
## 4 -0.08487125 -0.02267013  no 11.10500 3.1   11   2   0      no
## 5 -0.27536895 -0.09883644  no 11.10847 4.4   12   0   2      no
## 6 -0.28960434 -0.10213252 yes 11.02825 4.2   12   0   1      no</code></pre>
<p><code>dydx_lnnlinc</code> is a data frame with all individual marginal effect for the variable <code>lnnlinc</code>.
What if we compute the mean of this column?</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="statistical-models.html#cb57-1" aria-hidden="true" tabindex="-1"></a>dydx_lnnlinc <span class="sc">%&gt;%</span></span>
<span id="cb57-2"><a href="statistical-models.html#cb57-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="fu">mean</span>(dydx))</span></code></pre></div>
<pre><code>##   mean(dydx)
## 1 -0.1699424</code></pre>
<p>Let’s compare this to the average marginal effects:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="statistical-models.html#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(effects_logit_participation)</span></code></pre></div>
<pre><code>## Average marginal effects 
##      Term Contrast    Effect Std. Error z value   Pr(&gt;|z|)     2.5 %   97.5 %
## 1 lnnlinc    dY/dX -0.169942   0.041511 -4.0939 4.2424e-05 -0.251303 -0.08858
## 2     age    dY/dX -0.106408   0.017591 -6.0491 1.4563e-09 -0.140885 -0.07193
## 3    educ    dY/dX  0.006616   0.006039  1.0954    0.27335 -0.005222  0.01845
## 4     nyc    dY/dX -0.277466   0.033255 -8.3435 &lt; 2.22e-16 -0.342645 -0.21229
## 5     noc    dY/dX -0.004584   0.015378 -0.2981    0.76563 -0.034725  0.02556
## 6 foreign yes - no  0.283377   0.039840  7.1129 1.1360e-12  0.205292  0.36146
## 
## Model type:  glm 
## Prediction type:  response</code></pre>
<p>Yep, it’s the same! This is why we speak of <em>average marginal effects</em>. Now that we know why
these are called average marginal effects, let’s go back to interpreting them. This time,
let’s plot them, because why not:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="statistical-models.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(effects_logit_participation)</span></code></pre></div>
<p><img src="modern_R_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>So an infinitesimal increase, in say, non-labour income (<code>lnnlinc</code>) of 0.001 is associated with a
decrease of the probability of labour force participation by 0.001*17 percentage points.</p>
<p>This is just scratching the surface of interpreting these kinds of models. There are many more
types of effects that you can compute and look at. I highly recommend you read the documentation
of <code>{marginaleffects}</code> which you can find
<a href="https://vincentarelbundock.github.io/marginaleffects/index.html">here</a>. The author
of the package, Vincent Arel-Bundock writes a lot of very helpful documentation for his packages,
so if model interpretation is important for your job, definitely take a look.</p>
</div>
<div id="explainability-of-black-box-models" class="section level3 hasAnchor" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> Explainability of <em>black-box</em> models<a href="statistical-models.html#explainability-of-black-box-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Just read Christoph Molnar’s
<a href="https://christophm.github.io/interpretable-ml-book/">Interpretable Machine Learning</a>.</p>
<p>Seriously, I cannot add anything meaningful to it. His book is brilliant.</p>
</div>
</div>
<div id="comparing-models" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> Comparing models<a href="statistical-models.html#comparing-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Consider this section more as an illustration of what is possible with the knowledge you acquired
at this point. Imagine that the task at hand is to compare two models. We would like to select
the one which has the best fit to the data.
Let’s first estimate another model on the same data; prices are only positive, so a linear regression
might not be the best model, because the model could predict negative prices. Let’s look at the
distribution of prices:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="statistical-models.html#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(Housing) <span class="sc">+</span></span>
<span id="cb62-2"><a href="statistical-models.html#cb62-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(price))</span></code></pre></div>
<p><img src="modern_R_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>it looks like modeling the log of <code>price</code> might provide a better fit:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="statistical-models.html#cb63-1" aria-hidden="true" tabindex="-1"></a>model_log <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(price) <span class="sc">~</span> ., <span class="at">data =</span> Housing)</span>
<span id="cb63-2"><a href="statistical-models.html#cb63-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-3"><a href="statistical-models.html#cb63-3" aria-hidden="true" tabindex="-1"></a>result_log <span class="ot">&lt;-</span> broom<span class="sc">::</span><span class="fu">tidy</span>(model_log)</span>
<span id="cb63-4"><a href="statistical-models.html#cb63-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-5"><a href="statistical-models.html#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(result_log)</span></code></pre></div>
<pre><code>## # A tibble: 12 × 5
##    term          estimate  std.error statistic  p.value
##    &lt;chr&gt;            &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 (Intercept) 10.0       0.0472        212.   0       
##  2 lotsize      0.0000506 0.00000485     10.4  2.91e-23
##  3 bedrooms     0.0340    0.0145          2.34 1.94e- 2
##  4 bathrms      0.168     0.0206          8.13 3.10e-15
##  5 stories      0.0923    0.0128          7.20 2.10e-12
##  6 drivewayyes  0.131     0.0283          4.61 5.04e- 6
##  7 recroomyes   0.0735    0.0263          2.79 5.42e- 3
##  8 fullbaseyes  0.0994    0.0220          4.52 7.72e- 6
##  9 gashwyes     0.178     0.0446          4.00 7.22e- 5
## 10 aircoyes     0.178     0.0215          8.26 1.14e-15
## 11 garagepl     0.0508    0.0116          4.36 1.58e- 5
## 12 prefareayes  0.127     0.0231          5.50 6.02e- 8</code></pre>
<p>Let’s take a look at the diagnostics:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="statistical-models.html#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(model_log)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared sigma statistic   p.value    df logLik   AIC   BIC
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     0.677         0.670 0.214      102. 3.67e-123    11   73.9 -122. -65.8
## # … with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<p>Let’s compare these to the ones from the previous model:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="statistical-models.html#cb67-1" aria-hidden="true" tabindex="-1"></a>diag_lm <span class="ot">&lt;-</span> <span class="fu">glance</span>(model3)</span>
<span id="cb67-2"><a href="statistical-models.html#cb67-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-3"><a href="statistical-models.html#cb67-3" aria-hidden="true" tabindex="-1"></a>diag_lm <span class="ot">&lt;-</span> diag_lm <span class="sc">%&gt;%</span></span>
<span id="cb67-4"><a href="statistical-models.html#cb67-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;lin-lin model&quot;</span>)</span>
<span id="cb67-5"><a href="statistical-models.html#cb67-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-6"><a href="statistical-models.html#cb67-6" aria-hidden="true" tabindex="-1"></a>diag_log <span class="ot">&lt;-</span> <span class="fu">glance</span>(model_log)</span>
<span id="cb67-7"><a href="statistical-models.html#cb67-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-8"><a href="statistical-models.html#cb67-8" aria-hidden="true" tabindex="-1"></a>diag_log  <span class="ot">&lt;-</span> diag_log <span class="sc">%&gt;%</span></span>
<span id="cb67-9"><a href="statistical-models.html#cb67-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">model =</span> <span class="st">&quot;log-lin model&quot;</span>)</span>
<span id="cb67-10"><a href="statistical-models.html#cb67-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-11"><a href="statistical-models.html#cb67-11" aria-hidden="true" tabindex="-1"></a>diagnostics_models <span class="ot">&lt;-</span> <span class="fu">full_join</span>(diag_lm, diag_log) <span class="sc">%&gt;%</span></span>
<span id="cb67-12"><a href="statistical-models.html#cb67-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(model, <span class="fu">everything</span>()) <span class="co"># put the `model` column first</span></span></code></pre></div>
<pre><code>## Joining, by = c(&quot;r.squared&quot;, &quot;adj.r.squared&quot;, &quot;sigma&quot;, &quot;statistic&quot;, &quot;p.value&quot;, &quot;df&quot;,
## &quot;logLik&quot;, &quot;AIC&quot;, &quot;BIC&quot;, &quot;deviance&quot;, &quot;df.residual&quot;, &quot;nobs&quot;, &quot;model&quot;)</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="statistical-models.html#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(diagnostics_models)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 13
##   model r.squared adj.r.squared   sigma statistic   p.value    df  logLik    AIC
##   &lt;chr&gt;     &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
## 1 lin-…     0.673         0.666 1.54e+4      100. 6.18e-122    11 -6034.  12094.
## 2 log-…     0.677         0.670 2.14e-1      102. 3.67e-123    11    73.9  -122.
## # … with 4 more variables: BIC &lt;dbl&gt;, deviance &lt;dbl&gt;, df.residual &lt;int&gt;,
## #   nobs &lt;int&gt;</code></pre>
<p>I saved the diagnostics in two different <code>data.frame</code> objects using the <code>glance()</code> function and added a
<code>model</code> column to indicate which model the diagnostics come from. Then I merged both datasets using
<code>full_join()</code>, a <code>{dplyr}</code> function. Using this approach, we can easily build a data frame with the
diagnostics of several models and compare them. The model using the logarithm of prices has lower
AIC and BIC (and this higher likelihood), so if you’re worried about selecting the model with the better
fit to the data, you’d go for this model.</p>
</div>
<div id="using-a-model-for-prediction" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> Using a model for prediction<a href="statistical-models.html#using-a-model-for-prediction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Once you estimated a model, you might want to use it for prediction. This is easily done using the
<code>predict()</code> function that works with most models. Prediction is also useful as a way to test the
accuracy of your model: split your data into a training set (used for training) and a testing
set (used for the pseudo-prediction) and see if your model overfits the data. We are going to see
how to do that in a later section; for now, let’s just get acquainted with <code>predict()</code> and other
functions. I insist, keep in mind that this section is only to get acquainted with these functions.
We are going to explore prediction, overfitting and tuning of models in a later section.</p>
<p>Let’s go back to the models we trained in the previous section, <code>model3</code> and <code>model_log</code>. Let’s also
take a subsample of data, which we will be using for prediction:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="statistical-models.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb71-2"><a href="statistical-models.html#cb71-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-3"><a href="statistical-models.html#cb71-3" aria-hidden="true" tabindex="-1"></a>pred_set <span class="ot">&lt;-</span> Housing <span class="sc">%&gt;%</span></span>
<span id="cb71-4"><a href="statistical-models.html#cb71-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sample_n</span>(<span class="dv">20</span>)</span></code></pre></div>
<p>In order to always get the same <code>pred_set</code>, I set the random seed first. Let’s take a look at the
data:</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="statistical-models.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pred_set)</span></code></pre></div>
<pre><code>##      price lotsize bedrooms bathrms stories driveway recroom fullbase gashw
## 284  45000    6750        2       1       1      yes      no       no    no
## 101  57000    4500        3       2       2       no      no      yes    no
## 400  85000    7231        3       1       2      yes     yes      yes    no
## 98   59900    8250        3       1       1      yes      no      yes    no
## 103 125000    4320        3       1       2      yes      no      yes   yes
## 326  99000    8880        3       2       2      yes      no      yes    no
## 79   55000    3180        2       2       1      yes      no      yes    no
## 270  59000    4632        4       1       2      yes      no       no    no
## 382 112500    6550        3       1       2      yes      no      yes    no
## 184  63900    3510        3       1       2      yes      no       no    no
## 4    60500    6650        3       1       2      yes     yes       no    no
## 212  42000    2700        2       1       1       no      no       no    no
## 195  33000    3180        2       1       1      yes      no       no    no
## 511  70000    4646        3       1       2      yes     yes      yes    no
## 479  88000    5450        4       2       1      yes      no      yes    no
## 510  64000    4040        3       1       2      yes      no       no    no
## 424  62900    2880        3       1       2      yes      no       no    no
## 379  84000    7160        3       1       1      yes      no      yes    no
## 108  58500    3680        3       2       2      yes      no       no    no
## 131  35000    4840        2       1       2      yes      no       no    no
##     airco garagepl prefarea
## 284    no        0       no
## 101   yes        0       no
## 400   yes        0      yes
## 98     no        3       no
## 103    no        2       no
## 326   yes        1       no
## 79     no        2       no
## 270   yes        0       no
## 382   yes        0      yes
## 184    no        0       no
## 4      no        0       no
## 212    no        0       no
## 195    no        0       no
## 511    no        2       no
## 479   yes        0      yes
## 510    no        1       no
## 424    no        0      yes
## 379    no        2      yes
## 108    no        0       no
## 131    no        0       no</code></pre>
<p>If we wish to use it for prediction, this is easily done with <code>predict()</code>:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="statistical-models.html#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(model3, pred_set)</span></code></pre></div>
<pre><code>##       284       101       400        98       103       326        79       270 
##  51143.48  77286.31  93204.28  76481.82  77688.37 103751.72  66760.79  66486.26 
##       382       184         4       212       195       511       479       510 
##  86277.96  48042.41  63689.09  30093.18  38483.18  70524.34  91987.65  54166.78 
##       424       379       108       131 
##  55177.75  77741.03  62980.84  50926.99</code></pre>
<p>This returns a vector of predicted prices. This can then be used to compute the Root Mean Squared Error
for instance. Let’s do it within a <code>tidyverse</code> pipeline:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="statistical-models.html#cb76-1" aria-hidden="true" tabindex="-1"></a>rmse <span class="ot">&lt;-</span> pred_set <span class="sc">%&gt;%</span></span>
<span id="cb76-2"><a href="statistical-models.html#cb76-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">predictions =</span> <span class="fu">predict</span>(model3, .)) <span class="sc">%&gt;%</span></span>
<span id="cb76-3"><a href="statistical-models.html#cb76-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="fu">sqrt</span>(<span class="fu">sum</span>(predictions <span class="sc">-</span> price)<span class="sc">**</span><span class="dv">2</span><span class="sc">/</span><span class="fu">n</span>()))</span></code></pre></div>
<p>The root mean square error of <code>model3</code> is 3646.0817347.</p>
<p>I also used the <code>n()</code> function which returns the number of observations in a group (or all the
observations, if the data is not grouped). Let’s compare <code>model3</code> ’s RMSE with the one from
<code>model_log</code>:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="statistical-models.html#cb77-1" aria-hidden="true" tabindex="-1"></a>rmse2 <span class="ot">&lt;-</span> pred_set <span class="sc">%&gt;%</span></span>
<span id="cb77-2"><a href="statistical-models.html#cb77-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">predictions =</span> <span class="fu">exp</span>(<span class="fu">predict</span>(model_log, .))) <span class="sc">%&gt;%</span></span>
<span id="cb77-3"><a href="statistical-models.html#cb77-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="fu">sqrt</span>(<span class="fu">sum</span>(predictions <span class="sc">-</span> price)<span class="sc">**</span><span class="dv">2</span><span class="sc">/</span><span class="fu">n</span>()))</span></code></pre></div>
<p>Don’t forget to exponentiate the predictions, remember you’re dealing with a log-linear model! <code>model_log</code>’s
RMSE is 1.2125133^{4} which is lower than <code>model3</code>’s. However, keep in mind that the model was trained
on the whole data, and then the prediction quality was assessed using a subsample of the data the
model was trained on… so actually we can’t really say if <code>model_log</code>’s predictions are very useful.
Of course, this is the same for <code>model3</code>.
In a later section we are going to learn how to do cross validation to avoid this issue.</p>
<p>Just as a side note, notice that I had to copy and paste basically the same lines twice to compute
the predictions for both models. That’s not much, but if I wanted to compare 10 models, copy and
paste mistakes could have sneaked in. Instead, it would have been nice to have a function that
computes the RMSE and then use it on my models. We are going to learn how to write our own functions
and use it just like if it was another built-in R function.</p>
</div>
<div id="beyond-linear-regression" class="section level2 hasAnchor" number="6.7">
<h2><span class="header-section-number">6.7</span> Beyond linear regression<a href="statistical-models.html#beyond-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>R has a lot of other built-in functions for regression, such as <code>glm()</code> (for Generalized Linear
Models) and <code>nls()</code> for (for Nonlinear Least Squares). There are also functions and additional
packages for time series, panel data, machine learning, bayesian and nonparametric methods.
Presenting everything here would take too much space, and would be pretty useless as you can find
whatever you need using an internet search engine. What you have learned until now is quite general
and should work on many type of models. To help you out, here is a list of methods and the
recommended packages that you can use:</p>
<table>
<thead>
<tr class="header">
<th>Model</th>
<th>Package</th>
<th>Quick example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Robust Linear Regression</td>
<td><code>MASS</code></td>
<td><code>rlm(y ~ x, data = mydata)</code></td>
</tr>
<tr class="even">
<td>Nonlinear Least Squares</td>
<td><code>stats</code><a href="references.html#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></td>
<td><code>nls(y ~ x1 / (1 + x2), data = mydata)</code><a href="references.html#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></td>
</tr>
<tr class="odd">
<td>Logit</td>
<td><code>stats</code></td>
<td><code>glm(y ~ x, data = mydata, family = "binomial")</code></td>
</tr>
<tr class="even">
<td>Probit</td>
<td><code>stats</code></td>
<td><code>glm(y ~ x, data = mydata, family = binomial(link = "probit"))</code></td>
</tr>
<tr class="odd">
<td>K-Means</td>
<td><code>stats</code></td>
<td><code>kmeans(data, n)</code><a href="references.html#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></td>
</tr>
<tr class="even">
<td>PCA</td>
<td><code>stats</code></td>
<td><code>prcomp(data, scale = TRUE, center = TRUE)</code><a href="references.html#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></td>
</tr>
<tr class="odd">
<td>Multinomial Logit</td>
<td><code>mlogit</code></td>
<td>Requires several steps of data pre-processing and formula definition, refer to the <a href="https://cran.r-project.org/web/packages/mlogit/vignettes/mlogit.pdf">Vignette</a> for more details.</td>
</tr>
<tr class="even">
<td>Cox PH</td>
<td><code>survival</code></td>
<td><code>coxph(Surv(y_time, y_status) ~ x, data = mydata)</code><a href="references.html#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></td>
</tr>
<tr class="odd">
<td>Time series</td>
<td>Several, depending on your needs.</td>
<td>Time series in R is a vast subject that would require a very thick book to cover. You can get started with the following series of blog articles, <a href="http://www.business-science.io/timeseries-analysis/2017/07/02/tidy-timeseries-analysis.html">Tidy time-series, part 1</a>, <a href="http://www.business-science.io/timeseries-analysis/2017/07/23/tidy-timeseries-analysis-pt-2.html">Tidy time-series, part 2</a>, <a href="http://www.business-science.io/timeseries-analysis/2017/07/30/tidy-timeseries-analysis-pt-3.html">Tidy time-series, part 3</a> and <a href="http://www.business-science.io/timeseries-analysis/2017/08/30/tidy-timeseries-analysis-pt-4.html">Tidy time-series, part 4</a></td>
</tr>
<tr class="even">
<td>Panel data</td>
<td><code>plm</code></td>
<td><code>plm(y ~ x, data = mydata, model = "within|random")</code></td>
</tr>
<tr class="odd">
<td>Machine learning</td>
<td>Several, depending on your needs.</td>
<td>R is a very popular programming language for machine learning. <a href="https://www.tmwr.org/">This book</a> is a must read if you need to do machine learning with R.</td>
</tr>
<tr class="even">
<td>Nonparametric regression</td>
<td><code>np</code></td>
<td>Several functions and options available, refer to the <a href="https://cran.r-project.org/web/packages/np/vignettes/np.pdf">Vignette</a> for more details.</td>
</tr>
</tbody>
</table>
<p>I put neural networks in the table, but you can also find packages for regression trees, naive
bayes, and pretty much any machine learning method out there! The same goes for Bayesian methods.
Popular packages include <code>{rstan}</code>, <code>{rjags}</code> which link R to STAN and JAGS (two other pieces of software
that do the Gibbs sampling for you) which are tools that allow you to fit very general models. It
is also possible to train models using Bayesian inference without the need of external tools,
with the <code>{bayesm}</code> package which estimates the usual micro-econometric models.
There really are a lot of packages available for Bayesian inference, and you can find them all in the
<a href="https://cran.r-project.org/web/views/Bayesian.html">related CRAN Task View</a>.</p>
</div>
<div id="hyper-parameters" class="section level2 hasAnchor" number="6.8">
<h2><span class="header-section-number">6.8</span> Hyper-parameters<a href="statistical-models.html#hyper-parameters" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Hyper-parameters are parameters of the model that cannot be directly learned from the data.
A linear regression does not have any hyper-parameters, but a random forest for instance has several.
You might have heard of ridge regression, lasso and elasticnet. These are
extensions of linear models that avoid over-fitting by penalizing <em>large</em> models. These
extensions of the linear regression have hyper-parameters that the practitioner has to tune. There
are several ways one can tune these parameters, for example, by doing a grid-search, or a random
search over the grid or using more elaborate methods. To introduce hyper-parameters, let’s get
to know ridge regression, also called Tikhonov regularization.</p>
<div id="ridge-regression" class="section level3 hasAnchor" number="6.8.1">
<h3><span class="header-section-number">6.8.1</span> Ridge regression<a href="statistical-models.html#ridge-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ridge regression is used when the data you are working with has a lot of explanatory variables,
or when there is a risk that a simple linear regression might overfit to the training data, because,
for example, your explanatory variables are collinear.
If you are training a linear model and then you notice that it generalizes very badly to new,
unseen data, it is very likely that the linear model you trained overfit the data.
In this case, ridge regression might prove useful. The way ridge regression works might seem
counter-intuititive; it boils down to fitting a <em>worse</em> model to the training data, but in return,
this worse model will generalize better to new data.</p>
<p>The closed form solution of the ordinary least squares estimator is defined as:</p>
<p><span class="math display">\[
\widehat{\beta} = (X&#39;X)^{-1}X&#39;Y
\]</span></p>
<p>where <span class="math inline">\(X\)</span> is the design matrix (the matrix made up of the explanatory variables) and <span class="math inline">\(Y\)</span> is the
dependent variable. For ridge regression, this closed form solution changes a little bit:</p>
<p><span class="math display">\[
\widehat{\beta} = (X&#39;X + \lambda I_p)^{-1}X&#39;Y
\]</span></p>
<p>where <span class="math inline">\(\lambda \in \mathbb{R}\)</span> is an hyper-parameter and <span class="math inline">\(I_p\)</span> is the identity matrix of dimension <span class="math inline">\(p\)</span>
(<span class="math inline">\(p\)</span> is the number of explanatory variables).
This formula above is the closed form solution to the following optimisation program:</p>
<p><span class="math display">\[
\sum_{i=1}^n \left(y_i - \sum_{j=1}^px_{ij}\beta_j\right)^2
\]</span></p>
<p>such that:</p>
<p><span class="math display">\[
\sum_{j=1}^p(\beta_j)^2 &lt; c
\]</span></p>
<p>for any strictly positive <span class="math inline">\(c\)</span>.</p>
<p>The <code>glmnet()</code> function from the <code>{glmnet}</code> package can be used for ridge regression, by setting
the <code>alpha</code> argument to 0 (setting it to 1 would do LASSO, and setting it to a number between
0 and 1 would do elasticnet). But in order to compare linear regression and ridge regression,
let me first divide the data into a training set and a testing set:</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="statistical-models.html#cb78-1" aria-hidden="true" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(Housing)</span>
<span id="cb78-2"><a href="statistical-models.html#cb78-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-3"><a href="statistical-models.html#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb78-4"><a href="statistical-models.html#cb78-4" aria-hidden="true" tabindex="-1"></a>train_index <span class="ot">&lt;-</span> <span class="fu">sample</span>(index, <span class="fu">round</span>(<span class="fl">0.90</span><span class="sc">*</span><span class="fu">nrow</span>(Housing)), <span class="at">replace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb78-5"><a href="statistical-models.html#cb78-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-6"><a href="statistical-models.html#cb78-6" aria-hidden="true" tabindex="-1"></a>test_index <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(index, train_index)</span>
<span id="cb78-7"><a href="statistical-models.html#cb78-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-8"><a href="statistical-models.html#cb78-8" aria-hidden="true" tabindex="-1"></a>train_x <span class="ot">&lt;-</span> Housing[train_index, ] <span class="sc">%&gt;%</span> </span>
<span id="cb78-9"><a href="statistical-models.html#cb78-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(<span class="sc">-</span>price)</span>
<span id="cb78-10"><a href="statistical-models.html#cb78-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-11"><a href="statistical-models.html#cb78-11" aria-hidden="true" tabindex="-1"></a>train_y <span class="ot">&lt;-</span> Housing[train_index, ] <span class="sc">%&gt;%</span> </span>
<span id="cb78-12"><a href="statistical-models.html#cb78-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pull</span>(price)</span>
<span id="cb78-13"><a href="statistical-models.html#cb78-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-14"><a href="statistical-models.html#cb78-14" aria-hidden="true" tabindex="-1"></a>test_x <span class="ot">&lt;-</span> Housing[test_index, ] <span class="sc">%&gt;%</span> </span>
<span id="cb78-15"><a href="statistical-models.html#cb78-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(<span class="sc">-</span>price)</span>
<span id="cb78-16"><a href="statistical-models.html#cb78-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-17"><a href="statistical-models.html#cb78-17" aria-hidden="true" tabindex="-1"></a>test_y <span class="ot">&lt;-</span> Housing[test_index, ] <span class="sc">%&gt;%</span> </span>
<span id="cb78-18"><a href="statistical-models.html#cb78-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pull</span>(price)</span></code></pre></div>
<p>I do the train/test split this way, because <code>glmnet()</code> requires a design matrix as input, and not
a formula. Design matrices can be created using the <code>model.matrix()</code> function:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="statistical-models.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;glmnet&quot;</span>)</span>
<span id="cb79-2"><a href="statistical-models.html#cb79-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-3"><a href="statistical-models.html#cb79-3" aria-hidden="true" tabindex="-1"></a>train_matrix <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(train_y <span class="sc">~</span> ., <span class="at">data =</span> train_x)</span>
<span id="cb79-4"><a href="statistical-models.html#cb79-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-5"><a href="statistical-models.html#cb79-5" aria-hidden="true" tabindex="-1"></a>test_matrix <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(test_y <span class="sc">~</span> ., <span class="at">data =</span> test_x)</span></code></pre></div>
<p>Let’s now run a linear regression, by setting the penalty to 0:</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="statistical-models.html#cb80-1" aria-hidden="true" tabindex="-1"></a>model_lm_ridge <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">y =</span> train_y, <span class="at">x =</span> train_matrix, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">lambda =</span> <span class="dv">0</span>)</span></code></pre></div>
<p>The model above provides the same result as a linear regression, because I set <code>lambda</code> to 0. Let’s
compare the coefficients between the two:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="statistical-models.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(model_lm_ridge)</span></code></pre></div>
<pre><code>## 13 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                       s0
## (Intercept) -2667.542863
## (Intercept)     .       
## lotsize         3.397596
## bedrooms     2081.087654
## bathrms     13294.192823
## stories      6400.454580
## drivewayyes  6530.644895
## recroomyes   5389.856794
## fullbaseyes  4899.099463
## gashwyes    12575.611265
## aircoyes    13078.144146
## garagepl     4155.249461
## prefareayes 10260.781753</code></pre>
<p>and now the coefficients of the linear regression (because I provide a design matrix, I have to use
<code>lm.fit()</code> instead of <code>lm()</code> which requires a formula, not a matrix.)</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="statistical-models.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm.fit</span>(<span class="at">x =</span> train_matrix, <span class="at">y =</span> train_y))</span></code></pre></div>
<pre><code>##  (Intercept)      lotsize     bedrooms      bathrms      stories  drivewayyes 
## -2667.052098     3.397629  2081.344118 13293.707725  6400.416730  6529.972544 
##   recroomyes  fullbaseyes     gashwyes     aircoyes     garagepl  prefareayes 
##  5388.871137  4899.024787 12575.970220 13077.988867  4155.269629 10261.056772</code></pre>
<p>as you can see, the coefficients are the same. Let’s compute the RMSE for the unpenalized linear
regression:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="statistical-models.html#cb85-1" aria-hidden="true" tabindex="-1"></a>preds_lm <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_lm_ridge, test_matrix)</span>
<span id="cb85-2"><a href="statistical-models.html#cb85-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-3"><a href="statistical-models.html#cb85-3" aria-hidden="true" tabindex="-1"></a>rmse_lm <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(preds_lm <span class="sc">-</span> test_y)<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<p>The RMSE for the linear unpenalized regression is equal to 1731.5553157.</p>
<p>Let’s now run a ridge regression, with <code>lambda</code> equal to 100, and see if the RMSE is smaller:</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="statistical-models.html#cb86-1" aria-hidden="true" tabindex="-1"></a>model_ridge <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(<span class="at">y =</span> train_y, <span class="at">x =</span> train_matrix, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">lambda =</span> <span class="dv">100</span>)</span></code></pre></div>
<p>and let’s compute the RMSE again:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="statistical-models.html#cb87-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_ridge, test_matrix)</span>
<span id="cb87-2"><a href="statistical-models.html#cb87-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-3"><a href="statistical-models.html#cb87-3" aria-hidden="true" tabindex="-1"></a>rmse <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(preds <span class="sc">-</span> test_y)<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<p>The RMSE for the linear penalized regression is equal to 1726.7632312, which is smaller than before.
But which value of <code>lambda</code> gives smallest RMSE? To find out, one must run model over a grid of
<code>lambda</code> values and pick the model with lowest RMSE. This procedure is available in the <code>cv.glmnet()</code>
function, which picks the best value for <code>lambda</code>:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="statistical-models.html#cb88-1" aria-hidden="true" tabindex="-1"></a>best_model <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(train_matrix, train_y)</span>
<span id="cb88-2"><a href="statistical-models.html#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="co"># lambda that minimises the MSE</span></span>
<span id="cb88-3"><a href="statistical-models.html#cb88-3" aria-hidden="true" tabindex="-1"></a>best_model<span class="sc">$</span>lambda.min</span></code></pre></div>
<pre><code>## [1] 61.42681</code></pre>
<p>According to <code>cv.glmnet()</code> the best value for <code>lambda</code> is 61.4268056. In the
next section, we will implement cross validation ourselves, in order to find the hyper-parameters
of a random forest.</p>
</div>
</div>
<div id="training-validating-and-testing-models" class="section level2 hasAnchor" number="6.9">
<h2><span class="header-section-number">6.9</span> Training, validating, and testing models<a href="statistical-models.html#training-validating-and-testing-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Cross-validation is an important procedure which is used to compare models but also to tune the
hyper-parameters of a model. In this section, we are going to use several packages from the
<a href="https://github.com/tidymodels"><code>{tidymodels}</code></a> collection of packages, namely
<a href="https://tidymodels.github.io/recipes/"><code>{recipes}</code></a>,
<a href="https://tidymodels.github.io/rsample/"><code>{rsample}</code></a> and
<a href="https://tidymodels.github.io/parsnip/"><code>{parsnip}</code></a> to train a random forest the tidy way. I will
also use <a href="http://mlrmbo.mlr-org.com/"><code>{mlrMBO}</code></a> to tune the hyper-parameters of the random forest.</p>
<div id="set-up" class="section level3 hasAnchor" number="6.9.1">
<h3><span class="header-section-number">6.9.1</span> Set up<a href="statistical-models.html#set-up" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s load the needed packages:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="statistical-models.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;tidyverse&quot;</span>)</span>
<span id="cb90-2"><a href="statistical-models.html#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;recipes&quot;</span>)</span>
<span id="cb90-3"><a href="statistical-models.html#cb90-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;rsample&quot;</span>)</span>
<span id="cb90-4"><a href="statistical-models.html#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;parsnip&quot;</span>)</span>
<span id="cb90-5"><a href="statistical-models.html#cb90-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;yardstick&quot;</span>)</span>
<span id="cb90-6"><a href="statistical-models.html#cb90-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;brotools&quot;</span>)</span>
<span id="cb90-7"><a href="statistical-models.html#cb90-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;mlbench&quot;</span>)</span></code></pre></div>
<p>Load the data which is included in the <code>{mlrbench}</code> package:</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="statistical-models.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;BostonHousing2&quot;</span>)</span></code></pre></div>
<p>I will train a random forest to predict the housing prices, which is the <code>cmedv</code> column:</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="statistical-models.html#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(BostonHousing2)</span></code></pre></div>
<pre><code>##         town tract      lon     lat medv cmedv    crim zn indus chas   nox
## 1     Nahant  2011 -70.9550 42.2550 24.0  24.0 0.00632 18  2.31    0 0.538
## 2 Swampscott  2021 -70.9500 42.2875 21.6  21.6 0.02731  0  7.07    0 0.469
## 3 Swampscott  2022 -70.9360 42.2830 34.7  34.7 0.02729  0  7.07    0 0.469
## 4 Marblehead  2031 -70.9280 42.2930 33.4  33.4 0.03237  0  2.18    0 0.458
## 5 Marblehead  2032 -70.9220 42.2980 36.2  36.2 0.06905  0  2.18    0 0.458
## 6 Marblehead  2033 -70.9165 42.3040 28.7  28.7 0.02985  0  2.18    0 0.458
##      rm  age    dis rad tax ptratio      b lstat
## 1 6.575 65.2 4.0900   1 296    15.3 396.90  4.98
## 2 6.421 78.9 4.9671   2 242    17.8 396.90  9.14
## 3 7.185 61.1 4.9671   2 242    17.8 392.83  4.03
## 4 6.998 45.8 6.0622   3 222    18.7 394.63  2.94
## 5 7.147 54.2 6.0622   3 222    18.7 396.90  5.33
## 6 6.430 58.7 6.0622   3 222    18.7 394.12  5.21</code></pre>
<p>Only keep relevant columns:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="statistical-models.html#cb94-1" aria-hidden="true" tabindex="-1"></a>boston <span class="ot">&lt;-</span> BostonHousing2 <span class="sc">%&gt;%</span> </span>
<span id="cb94-2"><a href="statistical-models.html#cb94-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(<span class="sc">-</span>medv, <span class="sc">-</span>tract, <span class="sc">-</span>lon, <span class="sc">-</span>lat) <span class="sc">%&gt;%</span> </span>
<span id="cb94-3"><a href="statistical-models.html#cb94-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rename</span>(<span class="at">price =</span> cmedv)</span></code></pre></div>
<p>I remove <code>tract</code>, <code>lat</code> and <code>lon</code> because the information contained in the column <code>town</code> is enough.</p>
<p>To train and evaluate the model’s performance, I split the data in two.
One data set, called the training set, will be further split into two down below. I won’t
touch the second data set, the test set, until the very end, to finally assess the model’s
performance.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="statistical-models.html#cb95-1" aria-hidden="true" tabindex="-1"></a>train_test_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(boston, <span class="at">prop =</span> <span class="fl">0.9</span>)</span>
<span id="cb95-2"><a href="statistical-models.html#cb95-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-3"><a href="statistical-models.html#cb95-3" aria-hidden="true" tabindex="-1"></a>housing_train <span class="ot">&lt;-</span> <span class="fu">training</span>(train_test_split)</span>
<span id="cb95-4"><a href="statistical-models.html#cb95-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-5"><a href="statistical-models.html#cb95-5" aria-hidden="true" tabindex="-1"></a>housing_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(train_test_split)</span></code></pre></div>
<p><code>initial_split()</code>, <code>training()</code> and <code>testing()</code> are functions from the <code>{rsample}</code> package.</p>
<p>I will train a random forest on the training data, but the question, is <em>which</em> random forest?
Because random forests have several hyper-parameters, and as explained in the intro these
hyper-parameters cannot be directly learned from the data, which one should we choose? We could
train 6 random forests for instance and compare their performance, but why only 6? Why not 16?</p>
<p>In order to find the right hyper-parameters, the practitioner can
use values from the literature that seemed to have worked well (like is done in Macro-econometrics)
or you can further split the train set into two, create a grid of hyperparameter, train the model
on one part of the data for all values of the grid, and compare the predictions of the models on the
second part of the data. You then stick with the model that performed the best, for example, the
model with lowest RMSE. The thing is, you can’t estimate the true value of the RMSE with only
one value. It’s like if you wanted to estimate the height of the population by drawing one single
observation from the population. You need a bit more observations. To approach the true value of the
RMSE for a give set of hyperparameters, instead of doing one split, let’s do 30. Then we
compute the average RMSE, which implies training 30 models for each combination of the values of the
hyperparameters.</p>
<p>First, let’s split the training data again, using the <code>mc_cv()</code> function from <code>{rsample}</code> package.
This function implements Monte Carlo cross-validation:</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="statistical-models.html#cb96-1" aria-hidden="true" tabindex="-1"></a>validation_data <span class="ot">&lt;-</span> <span class="fu">mc_cv</span>(housing_train, <span class="at">prop =</span> <span class="fl">0.9</span>, <span class="at">times =</span> <span class="dv">30</span>)</span></code></pre></div>
<p>What does <code>validation_data</code> look like?</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="statistical-models.html#cb97-1" aria-hidden="true" tabindex="-1"></a>validation_data</span></code></pre></div>
<pre><code>## # Monte Carlo cross-validation (0.9/0.1) with 30 resamples  
## # A tibble: 30 × 2
##    splits           id        
##    &lt;list&gt;           &lt;chr&gt;     
##  1 &lt;split [409/46]&gt; Resample01
##  2 &lt;split [409/46]&gt; Resample02
##  3 &lt;split [409/46]&gt; Resample03
##  4 &lt;split [409/46]&gt; Resample04
##  5 &lt;split [409/46]&gt; Resample05
##  6 &lt;split [409/46]&gt; Resample06
##  7 &lt;split [409/46]&gt; Resample07
##  8 &lt;split [409/46]&gt; Resample08
##  9 &lt;split [409/46]&gt; Resample09
## 10 &lt;split [409/46]&gt; Resample10
## # … with 20 more rows</code></pre>
<p>Let’s look further down:</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="statistical-models.html#cb99-1" aria-hidden="true" tabindex="-1"></a>validation_data<span class="sc">$</span>splits[[<span class="dv">1</span>]]</span></code></pre></div>
<pre><code>## &lt;Analysis/Assess/Total&gt;
## &lt;409/46/455&gt;</code></pre>
<p>The first value is the number of rows of the first set, the second value of the second, and the third
was the original amount of values in the training data, before splitting again.</p>
<p>How should we call these two new data sets? The author of <code>{rsample}</code>, Max Kuhn, talks about
the <em>analysis</em> and the <em>assessment</em> sets, and I’m going to use this terminology as well.</p>
<p>Now, in order to continue I need to pre-process the data. I will do this in three steps.
The first and the second steps are used to center and scale the numeric variables and the third step
converts character and factor variables to dummy variables. This is needed because I will train a
random forest, which cannot handle factor variables directly. Let’s define a recipe to do that,
and start by pre-processing the testing set. I write a wrapper function around the recipe,
because I will need to apply this recipe to various data sets:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="statistical-models.html#cb101-1" aria-hidden="true" tabindex="-1"></a>simple_recipe <span class="ot">&lt;-</span> <span class="cf">function</span>(dataset){</span>
<span id="cb101-2"><a href="statistical-models.html#cb101-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">recipe</span>(price <span class="sc">~</span> ., <span class="at">data =</span> dataset) <span class="sc">%&gt;%</span></span>
<span id="cb101-3"><a href="statistical-models.html#cb101-3" aria-hidden="true" tabindex="-1"></a>        <span class="fu">step_center</span>(<span class="fu">all_numeric</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb101-4"><a href="statistical-models.html#cb101-4" aria-hidden="true" tabindex="-1"></a>        <span class="fu">step_scale</span>(<span class="fu">all_numeric</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb101-5"><a href="statistical-models.html#cb101-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">step_dummy</span>(<span class="fu">all_nominal</span>())</span>
<span id="cb101-6"><a href="statistical-models.html#cb101-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>We have not learned yet about writing functions, and will do so in the next chapter. However, for
now, you only need to know that you can write your own functions, and that these functions can
take any arguments you need. In the case of the above function, which we called <code>simple_recipe()</code>,
we only need one argument, which is a dataset, and which we called <code>dataset</code>.</p>
<p>Once the recipe is defined, I can use the <code>prep()</code> function, which estimates the parameters from
the data which are needed to process the data. For example, for centering, <code>prep()</code> estimates
the mean which will then be subtracted from the variables. With <code>bake()</code> the estimates are then
applied on the data:</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="statistical-models.html#cb102-1" aria-hidden="true" tabindex="-1"></a>testing_rec <span class="ot">&lt;-</span> <span class="fu">prep</span>(<span class="fu">simple_recipe</span>(housing_test), <span class="at">testing =</span> housing_test)</span>
<span id="cb102-2"><a href="statistical-models.html#cb102-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-3"><a href="statistical-models.html#cb102-3" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> <span class="fu">bake</span>(testing_rec, <span class="at">new_data =</span> housing_test)</span></code></pre></div>
<p>It is important to split the data before using <code>prep()</code> and <code>bake()</code>, because if not, you will
use observations from the test set in the <code>prep()</code> step, and thus introduce knowledge from the test
set into the training data. This is called data leakage, and must be avoided. This is why it is
necessary to first split the training data into an analysis and an assessment set, and then also
pre-process these sets separately. However, the <code>validation_data</code> object cannot now be used with
<code>recipe()</code>, because it is not a dataframe. No worries, I simply need to write a function that extracts
the analysis and assessment sets from the <code>validation_data</code> object, applies the pre-processing, trains
the model, and returns the RMSE. This will be a big function, at the center of the analysis.</p>
<p>But before that, let’s run a simple linear regression, as a benchmark. For the linear regression, I will
not use any CV, so let’s pre-process the training set:</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="statistical-models.html#cb103-1" aria-hidden="true" tabindex="-1"></a>trainlm_rec <span class="ot">&lt;-</span> <span class="fu">prep</span>(<span class="fu">simple_recipe</span>(housing_train), <span class="at">testing =</span> housing_train)</span>
<span id="cb103-2"><a href="statistical-models.html#cb103-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-3"><a href="statistical-models.html#cb103-3" aria-hidden="true" tabindex="-1"></a>trainlm_data <span class="ot">&lt;-</span> <span class="fu">bake</span>(trainlm_rec, <span class="at">new_data =</span> housing_train)</span>
<span id="cb103-4"><a href="statistical-models.html#cb103-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-5"><a href="statistical-models.html#cb103-5" aria-hidden="true" tabindex="-1"></a>linreg_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(price <span class="sc">~</span> ., <span class="at">data =</span> trainlm_data)</span>
<span id="cb103-6"><a href="statistical-models.html#cb103-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-7"><a href="statistical-models.html#cb103-7" aria-hidden="true" tabindex="-1"></a>broom<span class="sc">::</span><span class="fu">augment</span>(linreg_model, <span class="at">newdata =</span> test_data) <span class="sc">%&gt;%</span> </span>
<span id="cb103-8"><a href="statistical-models.html#cb103-8" aria-hidden="true" tabindex="-1"></a>    yardstick<span class="sc">::</span><span class="fu">rmse</span>(price, .fitted)</span></code></pre></div>
<pre><code>## Warning in predict.lm(x, newdata = newdata, na.action = na.pass, ...):
## prediction from a rank-deficient fit may be misleading</code></pre>
<pre><code>## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard       0.439</code></pre>
<p><code>broom::augment()</code> adds the predictions to the <code>test_data</code> in a new column, <code>.fitted</code>. I won’t
use this trick with the random forest, because there is no <code>augment()</code> method for random forests
from the <code>{ranger}</code> package which I’ll use. I’ll add the predictions to the data myself.</p>
<p>Ok, now let’s go back to the random forest and write the big function:</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="statistical-models.html#cb106-1" aria-hidden="true" tabindex="-1"></a>my_rf <span class="ot">&lt;-</span> <span class="cf">function</span>(mtry, trees, split, id){</span>
<span id="cb106-2"><a href="statistical-models.html#cb106-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb106-3"><a href="statistical-models.html#cb106-3" aria-hidden="true" tabindex="-1"></a>    analysis_set <span class="ot">&lt;-</span> <span class="fu">analysis</span>(split)</span>
<span id="cb106-4"><a href="statistical-models.html#cb106-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb106-5"><a href="statistical-models.html#cb106-5" aria-hidden="true" tabindex="-1"></a>    analysis_prep <span class="ot">&lt;-</span> <span class="fu">prep</span>(<span class="fu">simple_recipe</span>(analysis_set), <span class="at">training =</span> analysis_set)</span>
<span id="cb106-6"><a href="statistical-models.html#cb106-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb106-7"><a href="statistical-models.html#cb106-7" aria-hidden="true" tabindex="-1"></a>    analysis_processed <span class="ot">&lt;-</span> <span class="fu">bake</span>(analysis_prep, <span class="at">new_data =</span> analysis_set)</span>
<span id="cb106-8"><a href="statistical-models.html#cb106-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb106-9"><a href="statistical-models.html#cb106-9" aria-hidden="true" tabindex="-1"></a>    model <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">mode =</span> <span class="st">&quot;regression&quot;</span>, <span class="at">mtry =</span> mtry, <span class="at">trees =</span> trees) <span class="sc">%&gt;%</span></span>
<span id="cb106-10"><a href="statistical-models.html#cb106-10" aria-hidden="true" tabindex="-1"></a>        <span class="fu">set_engine</span>(<span class="st">&quot;ranger&quot;</span>, <span class="at">importance =</span> <span class="st">&#39;impurity&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb106-11"><a href="statistical-models.html#cb106-11" aria-hidden="true" tabindex="-1"></a>        <span class="fu">fit</span>(price <span class="sc">~</span> ., <span class="at">data =</span> analysis_processed)</span>
<span id="cb106-12"><a href="statistical-models.html#cb106-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-13"><a href="statistical-models.html#cb106-13" aria-hidden="true" tabindex="-1"></a>    assessment_set <span class="ot">&lt;-</span> <span class="fu">assessment</span>(split)</span>
<span id="cb106-14"><a href="statistical-models.html#cb106-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb106-15"><a href="statistical-models.html#cb106-15" aria-hidden="true" tabindex="-1"></a>    assessment_prep <span class="ot">&lt;-</span> <span class="fu">prep</span>(<span class="fu">simple_recipe</span>(assessment_set), <span class="at">testing =</span> assessment_set)</span>
<span id="cb106-16"><a href="statistical-models.html#cb106-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb106-17"><a href="statistical-models.html#cb106-17" aria-hidden="true" tabindex="-1"></a>    assessment_processed <span class="ot">&lt;-</span> <span class="fu">bake</span>(assessment_prep, <span class="at">new_data =</span> assessment_set)</span>
<span id="cb106-18"><a href="statistical-models.html#cb106-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-19"><a href="statistical-models.html#cb106-19" aria-hidden="true" tabindex="-1"></a>    tibble<span class="sc">::</span><span class="fu">tibble</span>(<span class="st">&quot;id&quot;</span> <span class="ot">=</span> id,</span>
<span id="cb106-20"><a href="statistical-models.html#cb106-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;truth&quot;</span> <span class="ot">=</span> assessment_processed<span class="sc">$</span>price,</span>
<span id="cb106-21"><a href="statistical-models.html#cb106-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;prediction&quot;</span> <span class="ot">=</span> <span class="fu">unlist</span>(<span class="fu">predict</span>(model, <span class="at">new_data =</span> assessment_processed)))</span>
<span id="cb106-22"><a href="statistical-models.html#cb106-22" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>The <code>rand_forest()</code> function is available in the <code>{parsnip}</code> package. This package provides an
unified interface to a lot of other machine learning packages. This means that instead of having to
learn the syntax of <code>range()</code> and <code>randomForest()</code> and, and… you can simply use the <code>rand_forest()</code>
function and change the <code>engine</code> argument to the one you want (<code>ranger</code>, <code>randomForest</code>, etc).</p>
<p>Let’s try this function:</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="statistical-models.html#cb107-1" aria-hidden="true" tabindex="-1"></a>results_example <span class="ot">&lt;-</span> <span class="fu">map2_df</span>(<span class="at">.x =</span> validation_data<span class="sc">$</span>splits,</span>
<span id="cb107-2"><a href="statistical-models.html#cb107-2" aria-hidden="true" tabindex="-1"></a>                           <span class="at">.y =</span> validation_data<span class="sc">$</span>id,</span>
<span id="cb107-3"><a href="statistical-models.html#cb107-3" aria-hidden="true" tabindex="-1"></a>                           <span class="sc">~</span><span class="fu">my_rf</span>(<span class="at">mtry =</span> <span class="dv">3</span>, <span class="at">trees =</span> <span class="dv">200</span>, <span class="at">split =</span> .x, <span class="at">id =</span> .y))</span></code></pre></div>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="statistical-models.html#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(results_example)</span></code></pre></div>
<pre><code>## # A tibble: 6 × 3
##   id           truth prediction
##   &lt;chr&gt;        &lt;dbl&gt;      &lt;dbl&gt;
## 1 Resample01 -0.328     -0.0274
## 2 Resample01  1.06       0.686 
## 3 Resample01  1.04       0.726 
## 4 Resample01 -0.418     -0.0190
## 5 Resample01  0.909      0.642 
## 6 Resample01  0.0926    -0.134</code></pre>
<p>I can now compute the RMSE when <code>mtry</code> = 3 and <code>trees</code> = 200:</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="statistical-models.html#cb110-1" aria-hidden="true" tabindex="-1"></a>results_example <span class="sc">%&gt;%</span></span>
<span id="cb110-2"><a href="statistical-models.html#cb110-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(id) <span class="sc">%&gt;%</span></span>
<span id="cb110-3"><a href="statistical-models.html#cb110-3" aria-hidden="true" tabindex="-1"></a>    yardstick<span class="sc">::</span><span class="fu">rmse</span>(truth, prediction) <span class="sc">%&gt;%</span></span>
<span id="cb110-4"><a href="statistical-models.html#cb110-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarise</span>(<span class="at">mean_rmse =</span> <span class="fu">mean</span>(.estimate)) <span class="sc">%&gt;%</span></span>
<span id="cb110-5"><a href="statistical-models.html#cb110-5" aria-hidden="true" tabindex="-1"></a>    pull</span></code></pre></div>
<pre><code>## [1] 0.6305034</code></pre>
<p>The random forest has already lower RMSE than the linear regression. The goal now is to lower this
RMSE by tuning the <code>mtry</code> and <code>trees</code> hyperparameters. For this, I will use Bayesian Optimization
methods implemented in the <code>{mlrMBO}</code> package.</p>
</div>
<div id="bayesian-hyperparameter-optimization" class="section level3 hasAnchor" number="6.9.2">
<h3><span class="header-section-number">6.9.2</span> Bayesian hyperparameter optimization<a href="statistical-models.html#bayesian-hyperparameter-optimization" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>I will re-use the code from above, and define a function that does everything from pre-processing
to returning the metric I want to minimize by tuning the hyperparameters, the RMSE:</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="statistical-models.html#cb112-1" aria-hidden="true" tabindex="-1"></a>tuning <span class="ot">&lt;-</span> <span class="cf">function</span>(param, validation_data){</span>
<span id="cb112-2"><a href="statistical-models.html#cb112-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-3"><a href="statistical-models.html#cb112-3" aria-hidden="true" tabindex="-1"></a>    mtry <span class="ot">&lt;-</span> param[<span class="dv">1</span>]</span>
<span id="cb112-4"><a href="statistical-models.html#cb112-4" aria-hidden="true" tabindex="-1"></a>    trees <span class="ot">&lt;-</span> param[<span class="dv">2</span>]</span>
<span id="cb112-5"><a href="statistical-models.html#cb112-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-6"><a href="statistical-models.html#cb112-6" aria-hidden="true" tabindex="-1"></a>    results <span class="ot">&lt;-</span> purrr<span class="sc">::</span><span class="fu">map2_df</span>(<span class="at">.x =</span> validation_data<span class="sc">$</span>splits,</span>
<span id="cb112-7"><a href="statistical-models.html#cb112-7" aria-hidden="true" tabindex="-1"></a>                       <span class="at">.y =</span> validation_data<span class="sc">$</span>id,</span>
<span id="cb112-8"><a href="statistical-models.html#cb112-8" aria-hidden="true" tabindex="-1"></a>                       <span class="sc">~</span><span class="fu">my_rf</span>(<span class="at">mtry =</span> mtry, <span class="at">trees =</span> trees, <span class="at">split =</span> .x, <span class="at">id =</span> .y))</span>
<span id="cb112-9"><a href="statistical-models.html#cb112-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-10"><a href="statistical-models.html#cb112-10" aria-hidden="true" tabindex="-1"></a>    results <span class="sc">%&gt;%</span></span>
<span id="cb112-11"><a href="statistical-models.html#cb112-11" aria-hidden="true" tabindex="-1"></a>        <span class="fu">group_by</span>(id) <span class="sc">%&gt;%</span></span>
<span id="cb112-12"><a href="statistical-models.html#cb112-12" aria-hidden="true" tabindex="-1"></a>        yardstick<span class="sc">::</span><span class="fu">rmse</span>(truth, prediction) <span class="sc">%&gt;%</span></span>
<span id="cb112-13"><a href="statistical-models.html#cb112-13" aria-hidden="true" tabindex="-1"></a>        <span class="fu">summarise</span>(<span class="at">mean_rmse =</span> <span class="fu">mean</span>(.estimate)) <span class="sc">%&gt;%</span></span>
<span id="cb112-14"><a href="statistical-models.html#cb112-14" aria-hidden="true" tabindex="-1"></a>        pull</span>
<span id="cb112-15"><a href="statistical-models.html#cb112-15" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>This is exactly the code from before, but it now returns the RMSE. Let’s try the function
with the values from before:</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="statistical-models.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tuning</span>(<span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">200</span>), validation_data)</span></code></pre></div>
<pre><code>## [1] 0.6319843</code></pre>
<p>I now follow the code that can be found in the <a href="https://arxiv.org/abs/1703.03373">arxiv</a> paper to
run the optimization. A simpler model, called the surrogate model, is used to look for promising
points and to evaluate the value of the function at these points. This seems somewhat similar
(in spirit) to the <em>Indirect Inference</em> method as described in
<a href="https://www.jstor.org/stable/2285076">Gourieroux, Monfort, Renault</a>.</p>
<p>If you don’t really get what follows, no worries, it is not really important as such. The idea
is simply to look for hyper-parameters in an efficient way, and bayesian optimisation provides
this efficient way. However, you could use another method, for example a grid search. This would not
change anything to the general approach. So I will not spend too much time explaining what is
going on below, as you can read the details in the paper cited above as well as the package’s
documentation. The focus here is not on this particular method, but rather showing you how you can
use various packages to solve a data science problem.</p>
<p>Let’s first load the package and create the function to optimize:</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="statistical-models.html#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;mlrMBO&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="statistical-models.html#cb116-1" aria-hidden="true" tabindex="-1"></a>fn <span class="ot">&lt;-</span> <span class="fu">makeSingleObjectiveFunction</span>(<span class="at">name =</span> <span class="st">&quot;tuning&quot;</span>,</span>
<span id="cb116-2"><a href="statistical-models.html#cb116-2" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">fn =</span> tuning,</span>
<span id="cb116-3"><a href="statistical-models.html#cb116-3" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">par.set =</span> <span class="fu">makeParamSet</span>(<span class="fu">makeIntegerParam</span>(<span class="st">&quot;x1&quot;</span>, <span class="at">lower =</span> <span class="dv">3</span>, <span class="at">upper =</span> <span class="dv">8</span>),</span>
<span id="cb116-4"><a href="statistical-models.html#cb116-4" aria-hidden="true" tabindex="-1"></a>                                                        <span class="fu">makeIntegerParam</span>(<span class="st">&quot;x2&quot;</span>, <span class="at">lower =</span> <span class="dv">100</span>, <span class="at">upper =</span> <span class="dv">500</span>)))</span></code></pre></div>
<p>This function is based on the function I defined before. The parameters to optimize are also
defined as are their bounds. I will look for <code>mtry</code> between the values of 3 and 8, and <code>trees</code>
between 50 and 500.</p>
<p>We still need to define some other objects before continuing:</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="statistical-models.html#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create initial random Latin Hypercube Design of 10 points</span></span>
<span id="cb117-2"><a href="statistical-models.html#cb117-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lhs)<span class="co"># for randomLHS</span></span>
<span id="cb117-3"><a href="statistical-models.html#cb117-3" aria-hidden="true" tabindex="-1"></a>des <span class="ot">&lt;-</span> <span class="fu">generateDesign</span>(<span class="at">n =</span> 5L <span class="sc">*</span> 2L, <span class="fu">getParamSet</span>(fn), <span class="at">fun =</span> randomLHS)</span></code></pre></div>
<p>Then we choose the surrogate model, a random forest too:</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="statistical-models.html#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify kriging model with standard error estimation</span></span>
<span id="cb118-2"><a href="statistical-models.html#cb118-2" aria-hidden="true" tabindex="-1"></a>surrogate <span class="ot">&lt;-</span> <span class="fu">makeLearner</span>(<span class="st">&quot;regr.ranger&quot;</span>, <span class="at">predict.type =</span> <span class="st">&quot;se&quot;</span>, <span class="at">keep.inbag =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>Here I define some options:</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="statistical-models.html#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set general controls</span></span>
<span id="cb119-2"><a href="statistical-models.html#cb119-2" aria-hidden="true" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">makeMBOControl</span>()</span>
<span id="cb119-3"><a href="statistical-models.html#cb119-3" aria-hidden="true" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">setMBOControlTermination</span>(ctrl, <span class="at">iters =</span> 10L)</span>
<span id="cb119-4"><a href="statistical-models.html#cb119-4" aria-hidden="true" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">setMBOControlInfill</span>(ctrl, <span class="at">crit =</span> <span class="fu">makeMBOInfillCritEI</span>())</span></code></pre></div>
<p>And this is the optimization part:</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="statistical-models.html#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Start optimization</span></span>
<span id="cb120-2"><a href="statistical-models.html#cb120-2" aria-hidden="true" tabindex="-1"></a>result <span class="ot">&lt;-</span> <span class="fu">mbo</span>(fn, des, surrogate, ctrl, <span class="at">more.args =</span> <span class="fu">list</span>(<span class="st">&quot;validation_data&quot;</span> <span class="ot">=</span> validation_data))</span></code></pre></div>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="statistical-models.html#cb121-1" aria-hidden="true" tabindex="-1"></a>result</span></code></pre></div>
<pre><code>## Recommended parameters:
## x1=8; x2=314
## Objective: y = 0.484
## 
## Optimization path
## 10 + 10 entries in total, displaying last 10 (or less):
##    x1  x2         y dob eol error.message exec.time            ei error.model
## 11  8 283 0.4855415   1  NA          &lt;NA&gt;     7.353 -3.276847e-04        &lt;NA&gt;
## 12  8 284 0.4852047   2  NA          &lt;NA&gt;     7.321 -3.283713e-04        &lt;NA&gt;
## 13  8 314 0.4839817   3  NA          &lt;NA&gt;     7.703 -3.828517e-04        &lt;NA&gt;
## 14  8 312 0.4841398   4  NA          &lt;NA&gt;     7.633 -2.829713e-04        &lt;NA&gt;
## 15  8 318 0.4841066   5  NA          &lt;NA&gt;     7.692 -2.668354e-04        &lt;NA&gt;
## 16  8 314 0.4845221   6  NA          &lt;NA&gt;     7.574 -1.382333e-04        &lt;NA&gt;
## 17  8 321 0.4843018   7  NA          &lt;NA&gt;     7.693 -3.828924e-05        &lt;NA&gt;
## 18  8 318 0.4868457   8  NA          &lt;NA&gt;     7.696 -8.692828e-07        &lt;NA&gt;
## 19  8 310 0.4862687   9  NA          &lt;NA&gt;     7.594 -1.061185e-07        &lt;NA&gt;
## 20  8 313 0.4878694  10  NA          &lt;NA&gt;     7.628 -5.153015e-07        &lt;NA&gt;
##    train.time prop.type propose.time           se      mean
## 11      0.011 infill_ei        0.450 0.0143886864 0.5075765
## 12      0.011 infill_ei        0.427 0.0090265872 0.4971003
## 13      0.012 infill_ei        0.443 0.0062693960 0.4916927
## 14      0.012 infill_ei        0.435 0.0037308971 0.4878950
## 15      0.012 infill_ei        0.737 0.0024446891 0.4860699
## 16      0.013 infill_ei        0.442 0.0012713838 0.4850705
## 17      0.012 infill_ei        0.444 0.0006371109 0.4847248
## 18      0.013 infill_ei        0.467 0.0002106381 0.4844576
## 19      0.014 infill_ei        0.435 0.0002182254 0.4846214
## 20      0.013 infill_ei        0.748 0.0002971160 0.4847383</code></pre>
<p>So the recommended parameters are 8 for <code>mtry</code> and 314 for <code>trees</code>. The
user can access these recommended parameters with <code>result$x$x1</code> and <code>result$x$x2</code>.
The value of the RMSE is lower than before, and equals 0.4839817. It can be accessed with
<code>result$y</code>.
Let’s now train the random forest on the training data with this values. First, I pre-process the
training data</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="statistical-models.html#cb123-1" aria-hidden="true" tabindex="-1"></a>training_rec <span class="ot">&lt;-</span> <span class="fu">prep</span>(<span class="fu">simple_recipe</span>(housing_train), <span class="at">testing =</span> housing_train)</span>
<span id="cb123-2"><a href="statistical-models.html#cb123-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-3"><a href="statistical-models.html#cb123-3" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">bake</span>(training_rec, <span class="at">new_data =</span> housing_train)</span></code></pre></div>
<p>Let’s now train our final model and predict the prices:</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="statistical-models.html#cb124-1" aria-hidden="true" tabindex="-1"></a>final_model <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">mode =</span> <span class="st">&quot;regression&quot;</span>, <span class="at">mtry =</span> result<span class="sc">$</span>x<span class="sc">$</span>x1, <span class="at">trees =</span> result<span class="sc">$</span>x<span class="sc">$</span>x2) <span class="sc">%&gt;%</span></span>
<span id="cb124-2"><a href="statistical-models.html#cb124-2" aria-hidden="true" tabindex="-1"></a>        <span class="fu">set_engine</span>(<span class="st">&quot;ranger&quot;</span>, <span class="at">importance =</span> <span class="st">&#39;impurity&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb124-3"><a href="statistical-models.html#cb124-3" aria-hidden="true" tabindex="-1"></a>        <span class="fu">fit</span>(price <span class="sc">~</span> ., <span class="at">data =</span> train_data)</span>
<span id="cb124-4"><a href="statistical-models.html#cb124-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb124-5"><a href="statistical-models.html#cb124-5" aria-hidden="true" tabindex="-1"></a>price_predict <span class="ot">&lt;-</span> <span class="fu">predict</span>(final_model, <span class="at">new_data =</span> <span class="fu">select</span>(test_data, <span class="sc">-</span>price))</span></code></pre></div>
<p>Let’s transform the data back and compare the predicted prices to the true ones visually:</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="statistical-models.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(price_predict <span class="sc">*</span> <span class="fu">sd</span>(housing_train<span class="sc">$</span>price) <span class="sc">+</span> <span class="fu">mean</span>(housing_train<span class="sc">$</span>price), </span>
<span id="cb125-2"><a href="statistical-models.html#cb125-2" aria-hidden="true" tabindex="-1"></a>      housing_test<span class="sc">$</span>price)</span></code></pre></div>
<pre><code>##       .pred housing_test$price
## 1  16.76938               13.5
## 2  27.59510               30.8
## 3  23.14952               24.7
## 4  21.92390               21.2
## 5  21.35030               20.0
## 6  23.15809               22.9
## 7  23.00947               23.9
## 8  25.74268               26.6
## 9  24.13122               22.6
## 10 34.97671               43.8
## 11 19.30543               18.8
## 12 18.09146               15.7
## 13 18.82922               19.2
## 14 18.63397               13.3
## 15 19.14438               14.0
## 16 17.05549               15.6
## 17 23.79491               27.0
## 18 20.30125               17.4
## 19 22.99200               23.6
## 20 32.77092               33.3
## 21 31.66258               34.6
## 22 28.79583               34.9
## 23 39.02755               50.0
## 24 23.53336               21.7
## 25 24.66551               24.3
## 26 24.91737               24.0
## 27 25.11847               25.1
## 28 24.42518               23.7
## 29 24.59139               23.7
## 30 24.91760               26.2
## 31 38.73875               43.5
## 32 29.71848               35.1
## 33 36.89490               46.0
## 34 24.04041               26.4
## 35 20.91349               20.3
## 36 21.18602               23.1
## 37 22.57069               22.2
## 38 25.21751               23.9
## 39 28.55841               50.0
## 40 14.38216                7.2
## 41 12.76573                8.5
## 42 11.78237                9.5
## 43 13.29279               13.4
## 44 14.95076               16.4
## 45 15.79182               19.1
## 46 18.26510               19.6
## 47 14.84985               13.3
## 48 16.01508               16.7
## 49 24.09930               25.0
## 50 20.75357               21.8
## 51 19.49487               19.7</code></pre>
<p>Let’s now compute the RMSE:</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="statistical-models.html#cb127-1" aria-hidden="true" tabindex="-1"></a>tibble<span class="sc">::</span><span class="fu">tibble</span>(<span class="st">&quot;truth&quot;</span> <span class="ot">=</span> test_data<span class="sc">$</span>price,</span>
<span id="cb127-2"><a href="statistical-models.html#cb127-2" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;prediction&quot;</span> <span class="ot">=</span> <span class="fu">unlist</span>(price_predict)) <span class="sc">%&gt;%</span> </span>
<span id="cb127-3"><a href="statistical-models.html#cb127-3" aria-hidden="true" tabindex="-1"></a>    yardstick<span class="sc">::</span><span class="fu">rmse</span>(truth, prediction)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard       0.425</code></pre>
<p>As I mentioned above, all the part about looking for hyper-parameters could be changed to something
else. The general approach though remains what I have described, and can be applied for any models
that have hyper-parameters.</p>

</div>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-breiman2001" class="csl-entry">
Breiman, Leo. 2001. <span>“Statistical Modeling: The Two Cultures (with Comments and a Rejoinder by the Author).”</span> <em>Statist. Sci.</em> 16 (3): 199–231. <a href="https://doi.org/10.1214/ss/1009213726">https://doi.org/10.1214/ss/1009213726</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="graphs.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="defining-your-own-functions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
